{"cells": [{"cell_type": "markdown", "id": "printable-ticket", "metadata": {}, "source": ["# Une analyse de la r\u00e9gularisation Ridge \u2615\ufe0f\u2615\ufe0f\u2615\ufe0f"]}, {"cell_type": "markdown", "id": "cultural-payment", "metadata": {}, "source": ["La r\u00e9gularisation Ridge, aussi appel\u00e9e *weight decay* en *deep learning* ou encore p\u00e9nalit\u00e9 $\\ell_2$, poss\u00e8de des propri\u00e9t\u00e9s fascinantes qui (1) expliquent ses performances et (2) permettent de la relier \u00e0 d'autres strat\u00e9gies de r\u00e9gularisation empiriques telles que la *data augmentation*, le ou encore le *dropout*.\n", "\n", "Nous nous concentrerons dans cette s\u00e9quence sur les probl\u00e8mes lin\u00e9aires."]}, {"cell_type": "markdown", "id": "smooth-gender", "metadata": {}, "source": ["## I. Ridge, une question de stabilit\u00e9"]}, {"cell_type": "markdown", "id": "saved-dancing", "metadata": {}, "source": ["Soit $X\\in\\mathbb{R}^{p\\times n}$ la matrice de nos donn\u00e9es avec $p$ individus en dimension $n$. Soit $\\boldsymbol{y}\\in\\mathbb{p}$ nos labels. Notre objectif est de trouver un vecteur $\\beta\\in\\mathbb{R}^n$ tel que la quantit\u00e9 suivante soit minimis\u00e9e : \n", "\n", "$$\\hat{\\beta}=\\text{argmin}_{\\beta\\in\\mathbb{R}^n}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2.$$\n", "\n", "Nous avons pu constater que si $X^TX$ \u00e9tait inversible, ce probl\u00e8me poss\u00e9dait une unique solution calculable en annulant le gradient :\n", "\n", "$$\\hat{\\beta}=(X^TX)^{-1}X^T\\boldsymbol{y}.$$\n", "\n", "Lorsque $X^TX$ n'est pas inversible, une solution (de norme minimale) est :\n", "\n", "$$\\hat{\\beta}=X^\\dagger \\boldsymbol{y},$$\n", "\n", "o\u00f9 $X^\\dagger$ est le pseudo-inverse de Moore-Penrose. Nous avons pu constater dans les s\u00e9quences pr\u00e9c\u00e9dentes que le nombre d'individus dans $X$ affectait consid\u00e9rablement notre estimation de $\\hat{\\beta}$ et cela \u00e9tait visible au travers de l'effet *double descente*. Nous illustrons ce ph\u00e9nom\u00e8ne \u00e0 nouveau ci-dessous. On g\u00e9n\u00e8re un jeu de donn\u00e9es synth\u00e9tique en jouant sur le nombre d'invididus dans notre jeu d'apprentissage."]}, {"cell_type": "code", "execution_count": 1, "id": "consolidated-export", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 2, "id": "simple-bulgaria", "metadata": {}, "outputs": [], "source": ["# dimension de l'espace\n", "d = 50\n", "# repetition de l'experience\n", "redo = 50\n", "\n", "# vrai parametre utilise pour generer nos donnees\n", "beta = np.random.uniform(-2, 2, size=(d, 1))\n", "\n", "mu = [0 for _ in range(d)]\n", "cov = np.diag([1 for _ in range(d)])\n", "\n", "test_size = 500\n", "X_test = np.random.multivariate_normal(mean=mu, cov=cov, size=test_size)\n", "y_test = np.dot(X_test, beta) + np.random.normal(0, 1, size=(test_size, 1))\n", "\n", "errors = []\n", "train_errors = []\n", "for m in range(1, 100):\n", "    error = 0\n", "    train_error = 0\n", "    for j in range(redo):\n", "        # dataset construction\n", "        X = np.random.multivariate_normal(mean=mu, cov=cov, size=m)\n", "        y = np.dot(X, beta) + np.random.normal(0, 1, size=(m, 1))\n", "        \n", "        # param estimation\n", "        beta_pinv = np.dot(np.linalg.pinv(X), y)\n", "        \n", "        # risk estimation\n", "        error += ((np.dot(X_test, beta_pinv)-y_test)**2).sum()/(test_size*redo)\n", "        train_error += ((np.dot(X, beta_pinv)-y)**2).sum()/(m*redo)\n", "    train_errors.append(train_error)\n", "    errors.append(error)"]}, {"cell_type": "code", "execution_count": 7, "id": "applied-consultation", "metadata": {}, "outputs": [], "source": ["def plot_losses(errors, train_errors):\n", "    plt.figure(figsize=(15, 7))\n", "    plt.subplot(1, 2, 1)\n", "    plt.plot([i for i in range(1, len(errors)+1)], errors, label=\"Risk estimation\")\n", "    plt.axvline(x=d, color='k', linewidth=2.0, linestyle='--', label='Dimension')\n", "    plt.legend()\n", "    plt.yscale('log')\n", "    plt.title('Test error')\n", "    plt.xlabel('Dataset size')\n", "    plt.ylabel('Error')\n", "    plt.subplot(1, 2, 2)\n", "    plt.plot([i for i in range(1, len(train_errors)+1)], train_errors, label=\"Train error\")\n", "    plt.axvline(x=d, color='k', linewidth=2.0, linestyle='--', label='Dimension')\n", "    plt.legend()\n", "    plt.xlabel('Dataset size')\n", "    plt.ylabel('Error')\n", "    plt.title('Train error')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": 8, "id": "graduate-metropolitan", "metadata": {}, "outputs": [{"data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAG5CAYAAAA3ci11AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABzcUlEQVR4nO3deXxU9b3/8ddnJjsJYQuEEFbZZJdEEFypexW1rbYurVpbo/3VatvbVu1ta9t7u932em2vthpba22vW9UqKK1btW4oJAjIDrKGBAhLQiBAkpnv749JQhIS1kzOnJn38/HwYebMmZMPhwzfvOe7mXMOERERERERiS8BrwsQERERERGRzqewJyIiIiIiEocU9kREREREROKQwp6IiIiIiEgcUtgTERERERGJQwp7IiIiIiIicUhhT0RERERikpn93cxu8LoOEb9S2BM5QWa2p8V/YTPb1+LxdcdxvTfN7MvRqFVERCTaOrNddM5d7Jz7U7RqFYl3SV4XIOJ3zrnMpq/NbD3wZefca95VdJCZGWDOuXCLY0nOuYZjuMYxnS8iIontaNvFWGpf2tbSXvt5hNcf0/kiXUU9eyJRYmYBM7vLzD42sx1m9rSZ9Wp8Ls3M/tJ4vMrM5ptZPzP7CXAmcH/jJ6D3d3Dt08zsvcbXLjKzc1o896aZ/cTM3gVqgWFm5szsq2a2GljdeN7NZrbGzHaa2Swzy2txjUPOFxERORFmdo6ZlZnZnWa2BfijmfU0sxfNrNLMdjV+nd/iNc2jXczsRjN7x8x+1XjuOjO7+DDfL8/Mnm289jozu73Fcz80s2ca2+LdwI0dtJ/TG9vo6sb/T29TW6vzO/+uiZwYhT2R6LkduAI4G8gDdgEPND53A5ANDAR6A7cC+5xz/w68DdzmnMt0zt3W9qJmNgB4CfhPoBfwLeBZM8tpcdoXgCIgC9jQeOwKYCowxsw+AfwM+CzQv/GcJ9t8q+bzj+cPLyIi0o5cIm3XYCLtVAD4Y+PjQcA+oN0POhtNBVYCfYD/Av7Q2KvWipkFgNnAImAAcC7wdTO7sMVplwPPAD2A/2s81rL9rCHS3v6GSFt9L/CSmfVucY322luRmKGwJxI9twD/7pwrc84dAH4IXGlmSUA9kYZjuHMu5Jwrdc7tPsrrfh6Y45yb45wLO+deBUqAT7Y451Hn3FLnXINzrr7x2M+cczudc/uA64BHnHMLGmu7G5hmZkNaXKPl+SIiIp0hDNzjnDvgnNvnnNvhnHvWOVfrnKsBfkLkQ9KObHDOPeycCwF/IvKBZb92zjsVyHHO/dg5V+ecWws8DFzd4py5zrnnG9vSprauuf0ELgBWO+f+3NiePgGsAGa2uEZ77a1IzNCcPZHoGQz8zcxajt8PEWmU/kykV+9JM+sB/IVIMDyahmIwcJWZtWxskoE3Wjze1M7rWh7LAxY0PXDO7TGzHUQ+/Vx/mGuIiIiciErn3P6mB2aWAfwPcBHQs/FwlpkFGwNdW1uavnDO1TZ26mW2c95gIM/MqlocCxIZPdPkaNrKtr11G4i0lYe7hkjMUNgTiZ5NwE3OuXc7eP5HwI8ae9PmEBmW8gfAHcV1/+ycu/kw57R3jZbHyok0hACYWTciPY2bj3ANERGRE9G2bfk3YBQw1Tm3xcwmAR8ChwzNPEabgHXOuRHHUEvbY63aykaDgH8c4RoiMUPDOEWi50HgJ2Y2GMDMcszs8savZ5jZeDMLAruJDOts+gRzK4ef5P0XYKaZXWhmwcbFXs5pOaH9KDwOfNHMJplZKvBT4APn3Ppj+hOKiIicmCwi8/SqGhcxu6eTrjsP2N24GEx6Y3s5zsxOPYZrzAFGmtm1ZpZkZp8jMo/9xU6qUSTqFPZEoufXwCzgFTOrAd4nMrEcIhPUnyES9JYD/yIS4pped2XjSmO/aXtR59wmIpPKvwtUEvn08tscw/vZOfc68H3gWaACOInW8xhERES6wn1AOrCdSDv5j8OefZQah4DOBCYB6xqv/3sii6Md7TV2AJcS6X3cAXwHuNQ5t70zahTpCuacep9FRERERETijXr2RERERERE4pDCnoiIiIiISBxS2BMREREREYlDCnsiIiIiIiJxyNf77PXp08cNGTLE6zJERCTKSktLtzvncryuw0/URoqIJIbDtZG+DHtmNhOYOXz4cEpKSrwuR0REoszMNnhdg98MGTJEbaSISAI4XBvpy2GczrnZzrmi7Oyj3ipFJC4UFxdTXFzsdRkiIiIxR22kyKF8vc9eYWGh06eWkkjMDAA/v29FjoeZlTrnCr2uw0/URkqiURspiepwbaQve/ZERERERETk8Hw/Z09EpK36+nrKysrYv3+/16XIMUpLSyM/P5/k5GSvS4lLem9El35+RSTW+DLsOedmA7MLCwtv9roWEYk9ZWVlZGVlMWTIkOZhPRL7nHPs2LGDsrIyhg4d6nU5cUnvjejRz6+IxCIN4xSRuLN//3569+6tX2Z9xszo3bu3ep2iSO+N6NHPr4jEIl+GPTObaWbF1dXVXpciIjFKv8z6k/7eok/3OHp0b0Uk1vgy7GnrBRERERERkcPzZdgTSVTOOS0p7RPBYJBJkyYxbtw4Zs6cSVVVFQDl5eVceeWVHb5u/fr1jBs3rlNrue+++6itrW1+/MlPfrK5nhOxcOFC5syZ0/x41qxZ/PznPz/h60p82rFjB5MmTWLSpEnk5uYyYMCA5sd1dXWHfW1JSQm33357F1UqfqU2UuRQCnsiIlGQnp7OwoULWbJkCb169eKBBx4AIC8vj2eeeaZLa2kb9ubMmUOPHj1O+Lptw95ll13GXXfddcLXlfjUu3dvFi5cyMKFC7n11lv5xje+0fw4JSWFhoaGDl9bWFjIb37zm06vKRQKHfbx0b5ORCRWKeyJiETZtGnT2Lx5M9C6527p0qVMmTKFSZMmMWHCBFavXt3qdWvXruWUU05h/vz5h1zzl7/8JaeeeioTJkzgnnvuAWDv3r1ccsklTJw4kXHjxvHUU0/xm9/8hvLycmbMmMGMGTMAGDJkCNu3b2f9+vWMHj2aL3/5y4wbN47rrruO1157jdNPP50RI0Ywb948AObNm8f06dM55ZRTmD59OitXrqSuro4f/OAHPPXUU0yaNImnnnqKRx99lNtuuw2ADRs2cO655zJhwgTOPfdcNm7cCMCNN97I7bffzvTp0xk2bFiXB1+JLTfeeCPf/OY3mTFjBnfeeWe7P2sAb775JpdeeikAP/zhD7nppps455xzGDZsWIch8JVXXmHatGlMnjyZq666ij179gCRn/8f//jHnHHGGfz1r3895PETTzzB+PHjGTduHHfeeWfz9TIzM/nBD37A1KlTmTt3bpTvjIhI5/Dl1gvaZ08SVUFBAQClpaUeV+IfP5q9lGXluzv1mmPyunPPzLFHdW4oFOL111/nS1/60iHPPfjgg9xxxx1cd9111NXVEQqF2Lp1KwArV67k6quv5o9//COTJk1q9bpXXnmF1atXM2/ePJxzXHbZZbz11ltUVlaSl5fHSy+9BEB1dTXZ2dnce++9vPHGG/Tp0+eQGtasWcNf//pXiouLOfXUU3n88cd55513mDVrFj/96U95/vnnGT16NG+99RZJSUm89tprfPe73+XZZ5/lxz/+MSUlJdx///0APProo83Xve2227j++uu54YYbeOSRR7j99tt5/vnnAaioqOCdd95hxYoVXHbZZYcd1irR4/V7o8mqVat47bXXCAaD7N69u92ftbZWrFjBG2+8QU1NDaNGjeIrX/lKq73ttm/fzn/+53/y2muv0a1bN37xi19w77338oMf/ACI7If3zjvvAHDXXXc1Py4vL+e0006jtLSUnj17csEFF/D8889zxRVXsHfvXsaNG8ePf/zjE7hDEk1qI0UO5cuwp332JFEtWLDA6xLkKO3bt49Jkyaxfv16CgoKOP/88w85Z9q0afzkJz+hrKyMT3/604wYMQKAyspKLr/8cp599lnGjj30F+dXXnmFV155hVNOOQWAPXv2sHr1as4880y+9a1vceedd3LppZdy5plnHrHOoUOHMn78eADGjh3Lueeei5kxfvx41q9fD0RC4w033MDq1asxM+rr64943blz5/Lcc88B8IUvfIHvfOc7zc9dccUVBAIBxowZ0xxuJXFdddVVBINB4Oh/1i655BJSU1NJTU2lb9++bN26lfz8/Obn33//fZYtW8bpp58OQF1dHdOmTWt+/nOf+1yr6zU9nj9/Pueccw45OTkAXHfddbz11ltcccUVBINBPvOZz3TeH1w6ndpIkUP5MuyJiBytY+1l6CxNc/aqq6u59NJLeeCBBw5ZYOLaa69l6tSpvPTSS1x44YX8/ve/Z9iwYWRnZzNw4EDefffddsOec467776bW2655ZDnSktLmTNnDnfffTcXXHBBc09GR1JTU5u/DgQCzY8DgUDzHKrvf//7zJgxg7/97W+sX7+ec84551hvR6sl6Vt+Ty2m4B2v3httdevWrfnro/1Za/kzFAwGD5nv55zj/PPP54knnjji92z5+HA/j2lpac2hVETELzRnT0QkirKzs/nNb37Dr371q0N6KdauXcuwYcO4/fbbueyyy1i8eDEAKSkpPP/88zz22GM8/vjjh1zzwgsv5JFHHmmeg7R582a2bdtGeXk5GRkZfP7zn+db3/pW86fcWVlZ1NTUHPefobq6mgEDBgCth2oe7rrTp0/nySefBOD//u//OOOMM477+0vi6Ohn7ViddtppvPvuu6xZswaA2tpaVq1adcTXTZ06lX/9619s376dUCjEE088wdlnn33cdYiIHM7isir21UV3wSeFPREfCoXVG+Inp5xyChMnTmwOP02eeuopxo0bx6RJk1ixYgXXX39983PdunXjxRdf5H/+53944YUXWr3uggsu4Nprr2XatGmMHz+eK6+8kpqaGj766KPmBV9+8pOf8L3vfQ+AoqIiLr744uYFWo7Vd77zHe6++25OP/30VqsQzpgxg2XLljUv0NLSb37zG/74xz8yYcIE/vznP/PrX//6uL63JJaOftaOVU5ODo8++ijXXHMNEyZM4LTTTmPFihVHfF3//v352c9+xowZM5g4cSKTJ0/m8ssvP+46REQ6sr8+xJW/m8t9rx35g6gTYX4cQtNigZab265eJxLPmobC7atrIC1Zw4k6snz5ck4++WSvy5Dj1N7fn5mVOucKPSopqszsIuDXQBD4vXPu522ePwd4AVjXeOg559wRVwkpLCx0JSUlrY7pvRF9usfeaWoj/fi7rSSe99fu4Ori9/nDDYWce3K/E7rW4dpIX/bsOedmO+eKsrOzvS5FxBMN6tkTiQtmFgQeAC4GxgDXmNmYdk592zk3qfE/LQcpIuJzH6zdiRkUDukV1e+jBVpEfGTKRVexrGK3hnGKxI8pwBrn3FoAM3sSuBxY5mlVIj50881apF38Y976HZyc253s9OQjn3wCFPZEfOSK23/E1n+tVdgTiR8DgE0tHpcBU9s5b5qZLQLKgW8555a2dzEzKwKKAAYNGtTJpYrEtuLiYq9LEDkqdQ1hSjfs4upTo//vtC+HcYokqlAoEvIawmGPKxGRTmLtHGv7ac4CYLBzbiLwv8DzHV3MOVfsnCt0zhU27RUnIiKx5aPN1eyvDzN1aHSHcILCnoivbFy1hANb1qCsJxI3yoCBLR7nE+m9a+ac2+2c29P49Rwg2cz6dF2JIv5QWlpKaWmp12WIHNG8dTsBOLULwp4vh3G2WI3T61JEutTD//Y5ABr+R/MSROLEfGCEmQ0FNgNXA9e2PMHMcoGtzjlnZlOIfFC7o8srFYlxhYWRxQi1GqfEunnrdnBSTjf6ZKZG/Xv5smdPq3FKotOcvdgXDAaZNGkSY8eOZeLEidx7772EG7tkS0pKuP322z2pa/r06Z58X2mfc64BuA14GVgOPO2cW2pmt5rZrY2nXQksaZyz9xvgaufj32b13hCRRBYKO0rW72LqsN5d8v182bMnkugU9mJfeno6CxcuBGDbtm1ce+21VFdX86Mf/YjCwsLmT6C72nvvvefJ95WONQ7NnNPm2IMtvr4fuL+r64oWvTdEJJEtr9hNzYGGLpmvBz7t2RNJdAp7/tK3b1+Ki4u5//77cc7x5ptvcumllwLwwx/+kBtuuIELLriAIUOG8Nxzz/Gd73yH8ePHc9FFF1FfXw9E5qKcffbZFBQUcOGFF1JRUQHAOeecw5133smUKVMYOXIkb7/9NgBLly5lypQpTJo0iQkTJrB69WoAMjMzgcgwp29/+9uMGzeO8ePH89RTTwHw5ptvcs4553DllVcyevRorrvuOg2JkqjRe0NEEs0HTfP1ory/XhOFPREfCukXjGNiZh3+13Kp7uLi4sOeeyKGDRtGOBxm27Zthzz38ccf89JLL/HCCy/w+c9/nhkzZvDRRx+Rnp7OSy+9RH19PV/72td45plnKC0t5aabbuLf//3fm1/f0NDAvHnzuO+++/jRj34EwIMPPsgdd9zBwoULKSkpIT8/v9X3fO6551i4cCGLFi3itdde49vf/nbzL8kffvgh9913H8uWLWPt2rW8++67J/Rnl9il94beGyISHdv3HOCZ0jLufm4xcz8+OM163rodDOyVTl6P9C6pQ8M4RXyoIaSw50cd9QJcfPHFJCcnM378eEKhEBdddBEA48ePZ/369axcuZIlS5Zw/vnnAxAKhejfv3/z6z/96U8DUFBQwPr16wGYNm0aP/nJTygrK+PTn/40I0aMaPU933nnHa655hqCwSD9+vXj7LPPZv78+XTv3p0pU6Y0/wI8adIk1q9fzxlnnNGp90KkJb03RCRevLN6O//96koWbqrCOUgOGn8tKeOnnxrPVYX5zFu3k0+M7tdl9SjsifiQhnEem6MdalVUVERRUVFUali7di3BYJC+ffuyfPnyVs+lpkZW4woEAiQnJzf3lAQCARoaGnDOMXbsWObOndvutZteHwwGaWhoAODaa69l6tSpvPTSS1x44YX8/ve/5xOf+ETzaw53T5qu1/aaEn/03tB7Q0Q6z5ptNdzy5xL6ZKXyjfNG8onRfRnYK4PbHl/Ad55dzNy1O9hVW8/UYV0zhBM0jFPEV6744WPk3nCfhnH6TGVlJbfeeiu33XbbcQ15GzVqFJWVlc2/0NbX17N06dLDvmbt2rUMGzaM22+/ncsuu4zFixe3ev6ss87iqaeeIhQKUVlZyVtvvcWUKVOOuTaRE6H3hnSmkpISSkpKvC5DElTN/nqK/lxKekqQJ4tO4/ZzRzBuQDbZ6ck8cuOpXDNlEH/7cDNAly3OAj7t2dM+e5Koeg0eTeq+berZ84F9+/YxadIk6uvrSUpK4gtf+ALf/OY3j+taKSkpPPPMM9x+++1UV1fT0NDA17/+dcaOHdvha5566in+8pe/kJycTG5uLj/4wQ9aPf+pT32KuXPnMnHiRMyM//qv/yI3N5cVK1YcV40iR0vvDYmWgoICr0uQBBUOO7759CI27Kjl/748lf7ZrefjJQcD/PRT4xjRN5PlFbsZ1Cujy2ozP68kVVhY6PQJjiSSG/84jzdXVvLEzacx7aSu2Z/Fj5YvX87JJ5/sdRlynNr7+zOzUuecN2vy+1R7baTeG9GneywSf8p21XLFA+/y8PWFnDKo5yHP/+/rq/nvV1fxg0vHcNMZQ7u8vsO1kRrGKeIj7z76U3b8438J+/hDGhERkWiI5txSSWxzPqpg+5465q7dcchzW3fv597XVnH5pDy+ePqQri/uCHw5jFMkUa156wUAGjSMU0REpJWHH34YoNW2ISKd4ZWlWwFYtaXmkOeWbK7GObh+2uAT3oomGtSzJ+JDoXDY6xJinp+HqCcy/b1Fn+5x9OjeisSf7XsOULpxFwArt+455PkVjQFwZL+sLq3raCnsifhQSFnvsNLS0tixY4d+8fIZ5xw7duwgLS3N61Lilt4b0aOfX5H49PryrTgHZwzvw8eVe2ho80vY8ord5PdMJyst2aMKD0/DOEV8SD17h5efn09ZWRmVlZVelyLHKC0trXnTaul8em9El35+ReLPq8u2MqBHOpdPyuOdNdvZsLOWk3Iym59fuaWG0bmx2asHCnsivqSevcNLTk5m6NCuXw1LJNbpvSEicvRq6xp4e/V2rp06iNG53YHIvL2msHegIcTa7Xu5cGyul2UeloZxivhQg3r2RERERKLqrVXbOdAQ5vwx/RjeNxMzWNVi3t6abXsIhR2j1LMnIp0hK38kB+pD2lRdRESkjcmTJ3tdgsSZV5ZtITs9mSlDepEUDDCoVwarth5ckXNFReTrk/sr7IlIJyj8+kOsrdyrsCciItJGaWmp1yVIHGkIhfnnim2cO7ovScHIYMiR/bJY2SLsrdxaQ0pSgCG9u3lV5hH5chinmc00s+Lq6mqvSxHpUk0hT2FPREREJHrmr99FVW09F4zt13xsVL8s1m3fy4GGEBBZiXNE38zmMBiLYreyw3DOzXbOFWVnZ3tdikiXaghFQp42VRcRERGJnleXbSU1KcBZI3Oaj43ol0ko7Fi3fS/QtBJnd69KPCoaxiniI+/dfS4A4cvXeVyJiIhIbDEzQJvby4kLhx1zPqrgzBE5ZKQcjEtNC7Gs3FJD36w0ttUciOltF8CnPXsiia6ph09EREREOte89TvZsns/l03Ka3V8WJ9MkgLGqq01rNiyG4DRMbw4C6hnT8SXNGdPREREJDpmLSonPTnIeSf3bXU8JSnA0D7dWLV1D727pQJoGKeIdL6QhqiIiIiIdLq6hjBzPqrggrH9Wg3hbDKyXxZLyqvpmZFM724p5GSlelDl0dMwThEfUs+eiIiISOd7Z00lVbX1XDYxr93nR/bLYuPOWj7cWBXzQzhBYU/ElxT2RERERDrfCwvLyU5P5swROe0+Pyo3E+dg9bY9jOoX20M4QWFPxJe09YKIiIhI56qta+DVZVv55Pj+pCS1H5NG9jvYm+eHnj3N2RPxkd4X3YZzEAqHvS5FREQkpjz00ENelyA+99rybdTWhTocwgkwuHc3UpIC1DWEY37bBVDYE/GNcNiROfEiAELKeiIiIq0UFRV5XYL43KyF5fTrnsqUob06PCcYMIbnZLJiy25G9FXYE5FO0nIFTvXsiYiIiHSe6tp6/rVqGzdMG0IwYIc9d8rQXqQkBUhPCXZRdcdPYU/EJ0JhR83CfwDQcPqtHlcjIiISW4qLiwH18Mnxee/j7dSHHBePzz3iud+75GTfbIOlsCfiEw1hx86X7wcg/JVbPK5GREQkttxyS6RtVNiT4/HhpipSggHGDcg+4rlJwYBvQpRW4xTxiVDo4CdIWo1TREREpPMs2LCLcQO6k5oU+0Mzj4XCnohPtJ6zp7AnIiIi0hnqGsIs3lzNKYN6el1Kp1PYE/GJhhaLsijsiYiIiHSO5RW7qWsIM1lhL3rM7Bwze9vMHjSzc7yuRyTWtAx4CnsiIiIix662ruGQYws27gLglEE9uria6Itq2DOzR8xsm5ktaXP8IjNbaWZrzOyuxsMO2AOkAWXRrEvEjxpazNnzywpQIiIiIl5zzvHGim189qG5TPjhKyzZXN3q+Q83VpHbPY28HukeVRg90V5I5lHgfuCxpgNmFgQeAM4nEurmm9ks4G3n3L/MrB9wL3BdlGsT8ZWw0wItIiIiIsfi9eVb+eXLK1mxpYa87DQCAeOp+Ztarbq5YOOuuOzVgyj37Dnn3gJ2tjk8BVjjnFvrnKsDngQud841TUjaBaR2dE0zKzKzEjMrqaysjErdIrGoIewYfOeLDL7zxVYrc4qIiEik98Zp5Iu08MS8jXz5sRLqQ2F+ddVE3vz2DC4cm8usReUcaAgBsK1mP2W79sXlfD3wZs7eAGBTi8dlwAAz+7SZPQT8mUhvYLucc8XOuULnXGFOTk6USxWJHa3m7KkxExEREenQo++u4+7nPuKckTm8dPuZXFmQT0pSgM9MHkD1vnreWLENiAzhhPicrwfebKpu7RxzzrnngOe6uhgRv2g1Z0/DOEVERETa9eC/Pubnf1/BBWP68b/XntJq77wzR+TQNyuVZ0o3c9G4/izYuIvkoB3VZup+5EXYKwMGtnicD5QfywXMbCYwc/jw4Z1Zl0hMCztHxaN3ANDw08c9rkZERCS2FBQUAFBaWupxJeKFPQcaeHFROU+VbOLDjVXMnJjHvZ+dSHKw9UDGYMD41CkD+MM769ix5wAfbqxiTP/upCXH12bqTbwIe/OBEWY2FNgMXA1ceywXcM7NBmYXFhbeHIX6RGJSQ9hRt/VjAMLq2RMREWllwYIFXpcgXaiieh/LK3azvKKGZRW7eWPFNmrrQpyU043vXXIyXzx9KMFAewMK4dOT83norbU8t2Azi8uquPrUQV1cfdeJatgzsyeAc4A+ZlYG3OOc+4OZ3Qa8DASBR5xzS6NZh0g8CLXYVL3lBusiIiIiiWTWonJuf+LD5scDeqRz6YT+fO7UgUwe1BOz9kNek1G5WYwb0J0H3lzD/vowkwfH5+IsEOWw55y7poPjc4A5x3tdDeOURKQ5eyIiIiLw8pIt5GSl8rvrJjMyN4vuacnHfI3PTM7nR7OXAXDKwB6dXGHs8GI1zhPmnJvtnCvKzo7PiZQi7Wm5AqfCnoiIiCSiUNjxzprtnD0yh8IhvY4r6AFcNjGPpICRk5VKfs/420y9iRdz9kTkOLTaekFhT0RERBLQR5urqd5Xz5kj+pzQdXpnpnLD9CGkJwePOOzTzxT2RHyiQfvsiYiISIJ7e1UlAGcMP7GwB/D9S8ec8DVinS/DnubsSSIKhRyZEy8kIyXYav6eiIiIwM03a5H2RPD26u2MG9Cd3pmpXpfiC74Me9p6QRJRyDl6X/Q1BvfO0DBOERGRNoqLi70uQaJsz4EGFmzcxc1nDfO6FN/w5QItIomoKeClJgU0jFNEREQSzvsf76Ah7E54vl4iUdgT8YmGsOPAljXsK1+jnj0REZE2SktLKS0t9boMiaK3V1eSnhykII73xetsvhzGqTl7kohC4TBb/vR1tgDTf/a61+WIiIjElMLCQgCcRr/ErbdXb+e0Yb1ITQp6XYpv+LJnT/vsSSIKhQ9+HVZDJiIiIglk085a1m7fy5kjcrwuxVd8GfZEElEofDDtNWgYp4iIiCSQd9ZsB+CskZqvdyx8OYxTJBE1aFN1ERERSRCrttbwp/fWk9cjnUG9MpjzUQW53dM4KSfT69J8RWFPxCdCCnsiIiKSIP73n2t4cXE5LWeufK5wIGbmXVE+5MuwpwVaJBEp7ImIiEgi2HOggVeXbeG6qYO4++KT2bizlrJd+7QK53Hw5Zw9LdAiiUhhT0RERBLBK0u3sL8+zBWTBtAtNYmT+3fn/DH96NUtxevSfMeXPXsiiagh7Mi94T5mTujPmzsU9kRERFoqKSnxugTpJC8sLCe/Z7p68jqBL3v2RBJRKOxIzR3O0NHjaWixMqeIiIhAQUEBBQUFXpchJ2j7ngO8s2Y7l03M0/y8TqCwJ+ITDaFIb15KUoCw06axIiIiEn9eXFROKOy44pQBXpcSFxT2RHwi5Bw7/vG/PPvrH0Qea96eSFwws4vMbKWZrTGzuw5z3qlmFjKzK7uyPhG/KCoqoqioyOsy5AQ9v7Cck/t3Z2S/LK9LiQu+DHtmNtPMiqurq70uRaTLhMJh9ix6mblznga0sbpIPDCzIPAAcDEwBrjGzMZ0cN4vgJe7tkIR/3j44Yd5+OGHvS5DTsD67XtZuKmKKybleV1K3PBl2NNqnJKI2oa7sIZxisSDKcAa59xa51wd8CRweTvnfQ14FtjWlcWJiHSlFxaWYwaXKex1Gl+GPZFEFAq1Dnfq2ROJCwOATS0elzUea2ZmA4BPAQ8e6WJmVmRmJWZWUllZ2amFiohEUyjseGHhZqYO7UX/7HSvy4kbCnsiPhFq05PXNvyJiC+1t9Rc2zf3fcCdzrnQkS7mnCt2zhU65wpzcnI6oz4RkS7x6HvrWbt9L58/bbDXpcQV7bMn4hNtF2RpG/5ExJfKgIEtHucD5W3OKQSebFyCvA/wSTNrcM493yUViohE2frte/nlyys4d3RfLhnf3+ty4orCnohPtB22qdU4ReLCfGCEmQ0FNgNXA9e2PME5N7TpazN7FHhRQU9E4kU47PjOs4tJDgb4yafGa2+9TqawJ+IToZAjI28E/bqnEkZhTyQeOOcazOw2IqtsBoFHnHNLzezWxuePOE9PRCImT57sdQlyHP7ywQbmrdvJf31mArnZaV6XE3cU9kR8IuQck772IN84fyTf+usihT2ROOGcmwPMaXOs3ZDnnLuxK2oS8aPS0lKvS5BjtGlnLT//+wrOGpnDVYX5XpcTl3y5QIv22ZNEFAo7ggEj2Piu1WqcIiIi4mePvreehrDjZ5/W8M1o8WXY0z57kogawo6kgBEMRN626tkTERERP1u4qYqJ+dkM6KGtFqLFl2FPJBGFwmHe+PYMLp80oPGxwp6IiEgTM1PvkI/Uh8Is2VzNhPweXpcS1xT2RHyibbhrCIc9qkRERETkxKzaWsOBhjATB/bwupS4prAn4hNtw56ynoiIiPjVok2RtTcm5mtaVjQp7In4RNsFWdSzJyIiIn61uKyKHhnJDOqV4XUpcU1hT8Qn2vbsac6eiIiIxLpnS8v49l8XHXJ84aYqJuT30DzLKFPYE/EJhT0RERHxk/pQmP96eQV/LS1jzbaa5uP76kKs3rZHQzi7gMKeiE+0HcapsCciIiKx7B9LtrB19wEAXlxc0Xx8aXk1obBjolbijLokrwsQkaMTCjumfOEuzh3dl8d3Q8gp7ImIiDR56KGHvC5B2nj0vfUM7p1Bv6w0XlxcwR3njsDMWLipCoAJA9WzF23q2RPxiYawY9Q5n+Kqz9/Y/FhEREQiioqKKCoq8roMafRRWTWlG3Zxw7QhzJyUx5pte1i5NTKUc3FZNXnZafTNSvO4yvinsCfiE+GwIylgBAORicyhkMKeiIiIxKZH31tPRkqQKwvzuWhsLgGDFxdFhnIuKqvSZupdxJdhz8xmmllxdXW116WIdJmGsGP1v/7Gc4//CdAwThERkZaKi4spLi72ugwBtu85wOxF5VxZkE/3tGRyslKZdlJvXvqogl1769iwo1ZDOLuIL8Oec262c64oO1s/JJI4QuEw7zz6M35059cbHyvsiYiINLnlllu45ZZbvC5DgCc+2EhdKMz104Y0H7t0Qh7rtu/lyfmbAJiknr0u4cuwJ5KIDt1UXWFPREREYkt9KMxfPtjAWSNzGN43s/n4RWNzCQaM376xBoBx2nahSyjsifhEuE24a/tYRERExGsrt9SwdfcBPjN5QKvjPbulcPrwPtQcaOCknG50T0v2qMLEorAn4hPq2RMREZFYt7px8/Qx/bsf8tylE/oDaH+9LqSwJ+ITbefohcJhjyoRERERad+qrXtIDhpD+nQ75LkLx+TSu1sKZ4/K8aCyxKRN1UV8om1PXkhZT0RERGLMqi01DOuTSXLw0D6l7IxkSr53HmbmQWWJST17Ij7Rdo6eevZEREQk1qzaVsOIfpkdPq+g17UU9kR8oiHsuOeFJezccwDQ1gsiIiItOedw2oPWU3sPNLBp5z5G9cvyuhRppLAn4hOhsCMYMILByCdiWqBFREREYsmabXsAGKGwFzMU9kR8oiEcJilgBBuHP6hnT0RERGLJyq2RlThHHmYYp3QthT0RnwiH4YE7ruTMaVMBCGmoioiISLOCggIKCgq8LiOhrd5aQ0pSgMG9D12JU7yh1ThFfKIhHGbzmmVsBgZfAKGQwp6IiEiTBQsWeF1Cwlu1dQ/DczIJBrQIS6xQz56ID4TDjrajNjVnT0RERGLJqq01jMrVfL1YorAn4gNth2wGDMIaxikiIiIeKa/a12r1093766mo3n/YbRek6ynsifhA28VYkgIB9eyJiIiIJ9Zv38vpv/gnzy/c3HxsdePiLNp2IbbEVNgzs25mVmpml3pdi0gsaRv2AgGtxikiIiLeWLW1BufgD++sa+7dW7U1su3CSIW9mBLVsGdmj5jZNjNb0ub4RWa20szWmNldLZ66E3g6mjWJ+FHbXrykQEBhT0RERDyxcWctAEs27+bDTVVAJACmJwcZ0CPdw8qkrWivxvkocD/wWNMBMwsCDwDnA2XAfDObBeQBy4C0KNck4jtNwe7sy65mZL8s3jf17ImIiLR08803e11Cwti0s5ZuKUHMjMfeW8/kQT1ZtbWGkf0yCWglzpgS1bDnnHvLzIa0OTwFWOOcWwtgZk8ClwOZQDdgDLDPzOY458Jtr2lmRUARwKBBg6JYvUjsaAp2X7r753zhtMFM/o9XFfZERERaKC4u9rqEhLFxZy1D+nTj1CG9ePyDjfz7JQdYtXUPZ4/M8bo0acOLOXsDgE0tHpcBA5xz/+6c+zrwOPBwe0EPwDlX7JwrdM4V5uToB0oSQ1OwS2r8tCwYMC3QIiIiIp7YuLOWQb0y+Pxpg6kLhXnwXx9TWXNAi7PEIC82VW+vb7f5t1bn3KNdV4qIPzSEI599bFj5EaXBSoJmhMLtfh4iIiKSkEpLSwEoKCjwuJL4Fg47Nu3ax3kn92N430zOGN6HP723HkDbLsQgL3r2yoCBLR7nA+XHcgEzm2lmxdXV1Z1amEisaurZu/v6SyksLCQYMELKeiIiIs0KCwspLCz0uoy4t63mAHUNYQb2ygDg+mmDm0cbaUP12ONF2JsPjDCzoWaWAlwNzDqWCzjnZjvnirKzs6NSoEisOWQ1zqB69kRERKTrNa3EOagx7J17cj8G9EgnKzWJ3O5aZzHWRHUYp5k9AZwD9DGzMuAe59wfzOw24GUgCDzinFsazTpE/C7cJuwFTXP2REREpOu1DXvBgPGfV4yjrGofZlqJM9ZEezXOazo4PgeYc7zXNbOZwMzhw4cf7yVEfKVtsAsGjLBT2BMREZGutXFnLQGDvBb76c0Y3dfDiuRwvBjGecI0jFMSTdttFoIBoyGksCciIiJda9POWvpnp5OS5MsYkXD0tyTiA+317GmfPREREelqG3fWMrBX+pFPlJigsCfiA22DXVLACGkYp4iIiHSxpj32xB+82GfvhGnOniSaprD3+7+9xqSBPfjPD/arZ09ERKSFkpISr0uIe/vqQlTWHFDY8xFf9uxpzp4kmqZN1cdOmERBQUGkZ09hT0REpFlBQYE2VI+yTbsiK3EOVNjzDV+GPZFE0xTsggFr/r+2XhAREZGutHFH620XJPb5chinSKJpCns/++436JOZSnDKTdTXa1N1ERGRJkVFRQAUFxd7XEn8arvHnsQ+X4Y9zdmTRNMU9v72xGMAfOG0LxMKh7wsSUREJKY8/PDDgMJeNG3cWUu3lCC9uqV4XYocJV8O49ScPUk0bYdsas6eiIiIdLVNO2sZ2CsDM/O6FDlKvgx7IommbbALmObsiYiISNfStgv+o7An4gPt7bMXVtgTERGRLuKcU9jzIYU9ER9oG/aCQWvejkFEREQk2iprDnCgIcyg3gp7fqKwJ+IDbYdsBk1z9kRERKTrNK3EqT32/EWrcYr4QKixF2/8xEkkBwORBVqcwp6IiEiTyZMne11C3Ni1t44/vree15dv5XOnDuTzUwdr2wWf8mXYc87NBmYXFhbe7HUtIl0h1Dhi89W35tKvexrf+usiQiGFPRERkSalpaVel+B7lTUHePjttfzl/Q3U1oUY1qcbP3hhKbMWljOoVwZmMKBHutdlyjHwZdgTSTRNPXvBQGSpY/XsiYiISGeat24nt/6llKraOi6bmMdXzhnOyH6ZPLtgM//x4jJKNuyif3YaaclBr0uVY6CwJ+IDTXP2khrDXlD77ImIiEgneWLeRr7//BIG9crgqaLTGNEvq/m5KwvyOXtkDj/7+3L16vmQwp6IDzQFu57dUgH4/vMfaZ89ERGRFpo2+nYa+XLUQmHHj2cv5U9zN3DWyBz+95pTyE5PPuS8nKxU7v3spK4vUE6Ywp6IDxyy9YJ69kREROQEPf/hZv40dwNfOmMo3/3kyc3TRSR++HLrBTObaWbF1dXVXpci0iXa9uIlKeyJiIjICXpq/iaG9enG9y5R0ItXvgx7zrnZzrmi7Oxsr0sR6RJtg10gYBrGKSIiIsdtbeUe5q3fyVWFA5uHwEr88WXYE0k07fXshRX2ROKCmV1kZivNbI2Z3dXO85eb2WIzW2hmJWZ2hhd1ikh8ebqkjGDA+EzBAK9LkSjSnD0RHwiHXavhFcFAgIawwzmnT+NEfMzMgsADwPlAGTDfzGY555a1OO11YJZzzpnZBOBpYHTXVysi8aI+FOaZ0jJmjOpL36w0r8uRKFLPnogPNLQNe40BT517Ir43BVjjnFvrnKsDngQub3mCc26PO7i8YDdA73wROSFvrNjG9j0H+NypA70uRaJMPXsiPhAKh0kKGA899BAA9UFrPO40oVrE3wYAm1o8LgOmtj3JzD4F/AzoC1zS0cXMrAgoAhg0aFCnFioS65raSDlU9b76VlsqPF2yiZysVGaMyvGwKukKCnsiPtDUs1dUVATA7978GDh04RYR8Z32Pq055I3tnPsb8DczOwv4D+C89i7mnCsGigEKCwv1D4QklKY2Ulr754qt3PRoCZdM6M+dF44mLTnAGysrufnMYSQFNcgv3insifhA2zl7SY1fh7RxrIjflQEtx1HlA+Udneyce8vMTjKzPs657VGvTkR8718rK0kJBvjn8m28unQrY/K6Ewo7PluY73Vp0gV8Gee1z54kmoawIylgFBcXU1xc3Bz8QiGFPRGfmw+MMLOhZpYCXA3ManmCmQ23xpWYzGwykALs6PJKRWJcUxsprZVs2EXhkJ688a1zuOKUPBaVVTF1aC+G5WR6XZp0AV/27DnnZgOzCwsLb/a6FpGu0DQ375ZbbgHg0XfXAdAQDntZloicIOdcg5ndBrwMBIFHnHNLzezWxucfBD4DXG9m9cA+4HMtFmwRkUZNbaSGcx6090ADyyt2c9uM4eRmp/FfV07kqzOGk5nqywggx0F/0yI+EOnZO9gRH9QwTpG44ZybA8xpc+zBFl//AvhFV9clIv63aFMVYQeTB/dsPja4dzcPK5Ku5sthnCKJJhx2tMh6B+fsaYEWERER6UDJhl2YwSmDeh75ZIlLCnsiPtC2Zy/QGPYaNGdPREREOlC6YRcj+2a12nZBEovCnogPtN1Pr6lnL6xhnCIiItKOcNixYOOuVkM4JfEo7In4QEPjpupNmoJfg4ZxioiISDtWb9tDzf4GChT2EprCnogPhMIQsEPDnubsiYiISHtKN+wCoFBhL6Ep7In4QCgcJiloOOdwzmmBFhERkTaa2kiJKNmwk97dUhjcO8PrUsRDCnsiPtDQZs5eUy+fwp6IiIi0Z8GGXRQM7om1GBkkiUdhT8QHQmHXas5eUlBz9kRERKR92/ccYP2OWs3XE3+GPTObaWbF1dXVXpci0iVCYUfAjIKCAgoKCgg2bsOgnj0REZGIpjZSDs7XU9iTJK8LOB7OudnA7MLCwpu9rkWkK4TCjtTkAAsWLAAgqGGcIiIirTS1kRIZwpkSDDBuQLbXpYjHfNmzJ5JoInP2Dr5dtRqniIiIdKRkwy7GDehOWnLQ61LEYwp7Ij7Q0Zw9hT0RERFpafueAyzcVMX0k/p4XYrEAIU9ER/oaDXOhnDYq5JEREQkBs35qIJQ2DFzYp7XpUgMUNgT8YFw2DXP0wOae/nC2k9IREREWpi1sJxR/bIYlZvldSkSAxT2RHygIRwmGDwY9pp6+RpCCnsiIiISsblqHyUbdnHZJPXqSYQvV+MUSTRNc/ZuvjmyAK0WaBEREWmtqY1MZLMXlQMwc4LCnkQo7In4QNOcveLiYgBWb60BIKRhnCIiIgDNbWQim7WwnEkDezCod4bXpUiMOOIwTjMLmNn0rihGRNrXds5eQD17IjFH7aWIeGnNthqWVezmMi3MIi0cMew558LAf3dBLSLSgYawIylolJaWUlpa2rxAi+bsicQOtZci3mpqIxPVrIXlBAwundDf61IkhhztMM5XzOwzwHPOadyYSFcLNQ7jLCwsBGDTzr2R43o7isQatZciHmlqIxPxreecY9aick4b1pu+3dO8LkdiyNGGvW8C3YCQme0DDHDOue5Rq0xEmjWEHUmBgx3xWqBFJGapvRSRLvfR5mrW76jl1rNP8roUiTFHFfacc9qoQ8RD4bBr3kgdFPZEYpXaSxHxwvMflpMcNC4al+t1KRJjjno1TjO7DDir8eGbzrkXo1OSiLTVNGevSVMvn8KeSOxReykiXakhFGbWonI+MbovPTJSvC5HYsxRbapuZj8H7gCWNf53R+MxEekCTXP2mjStzNmgsCcSU9ReikhXe3vNdrbvOcCnTsn3uhSJQUfbs/dJYFLjSmOY2Z+AD4G7OqsQMzuZSAPZB3jdOfe7zrq2iN81hMPNK3ACBBt7+cIKeyKxJurtpYhIS39bsJkeGcnMGJ3jdSkSg46qZ69RjxZfZx/NC8zsETPbZmZL2hy/yMxWmtkaM7sLwDm33Dl3K/BZoPAY6hKJa845wo7Wc/bUsycSy3q0+Pqo2ksRkeOx50ADryzbwqUT+pOaFPS6HIlBR9uz91PgQzN7g8jKYmcBdx/F6x4F7gceazpgZkHgAeB8oAyYb2aznHPLGuc53NX4GhHh4Ly8pIBRUlICtFygJexZXSLSruNtL0XkBDW1kYnk7x9VsL8+rCGc0qEjhj0zCwBh4DTgVCKN153OuS1Heq1z7i0zG9Lm8BRgjXNubeP1nwQuB5Y552YBs8zsJeDxY/mDiMSrpt67YNAoKCgADg7fDCnricSME2kvReTENbWRieS5BZsZ0juDyYN6eF2KxKgjhj3nXNjMbnPOPQ3M6oTvOQDY1OJxGTDVzM4BPg2kAnM6erGZFQFFAIMGDeqEckRiW8uevSYB9eyJxJwotJciIh0qr9rH++t2cMe5I7AWUz1EWjraYZyvmtm3gKeAvU0HnXM7j+N7tvfT6JxzbwJvHunFzrlioBigsLBQE5Yk7oVc5Mc8YEZRUREAxcXFJAVMc/ZEYk9ntpcicgxatpGJ4PmFm3EOPq0hnHIYRxv2bmr8/1dbHHPAsOP4nmXAwBaP84Hy47iOSEIIhQ727D388MNApCELBqw5CIpIzOjM9lJEjkHLNjLehcKOZ0vLKBzck0G9M7wuR2LY0c7Zu8s591Qnfc/5wAgzGwpsBq4Grj2WC5jZTGDm8OHDO6kkkdh1cM5e68VzgwFrDoIi4r0otJciIu16pnQTH1fu5TfXjPS6FIlxR9x6oXGvoK8e6bz2mNkTwFxglJmVmdmXnHMNwG3Ay8By4Gnn3NJjua5zbrZzrig7WytaS/xrb84eoJ49kRhzIu2liEh7XlpcwcYdta2O7d5fzy9fXknh4J7MnNDfo8rEL6I6Z885d00Hx+dwmEVYROSgpkAXbDP5OilgzUFQRGKG5uyJSKfYtbeOrz6+gNzuafz11mkM7BUZrnn/P9ewY28df7xxihZmkSPyYs7eCdMwTkkkTUM1g+307GmBFpGYE1PtpYj414ebdgGwfc8BPv+HD/jrLdPYc6CBP767js8WDGR8vka4yZEdVdhzzg2NdiHHwjk3G5hdWFh4s9e1iERbQ+P2CknBQ8NeWGFPJKbEWnspIv5VumEXSQHjsZum8OXHSvjCH+aRk5VKWlKQb104yuvyxCcOO2fPzL7T4uur2jz302gVJSIHNQ3VDAaMyZMnM3ny5MhjU8+eSKxQeynivZZtZDwo3bCLsXndmT68Dw9fX8i67Xt5Z812bj93BDlZqV6XJz5xpAVarm7x9d1tnruok2sRkXa0nLNXWlpKaWlp5HFQc/ZEYojaSxGPtWwj/a4+FGbRpmomD+4JwOnD+/DQ9QV8rnAgN0wf4m1x4itHGsZpHXzd3uMuozl7kkgaOpizlxQIKOyJxI6YbC9FxJ9WVNSwrz5EQWPYA5gxqi8zRvX1sCrxoyP17LkOvm7vcZfR1guSSJq3XmgzZy9gKOyJxI6YbC9FxJ9KN0QW8G0Z9kSOx5F69iaa2W4in0qmN35N4+O0qFYmIkCLTdUDgeYllp1zJAUCzYu3iIjn1F6KeKxlG+l3pRuryMtOo392uteliM8dNuw554JdVYiItC/sDrOpurKeSExQeykinWnBhl3N8/VETsSRhnHGJDObaWbF1dXVXpciEnVNc/YC1l7YU9oTERGJJxXV+9hctU9DOKVT+DLsac6eJJKO5uwFA0bI/yNVREREpIXSDZHN1BX2pDP4MuyJJJKmeXmHrsapnj0REZF4U7phF2nJAU7u393rUiQOKOyJxLiO5uwFAtY8xFNERETiw4INu5iY34PkoH5NlxOnnyKRGNfRnL2kgDUHQREREfG/fXUhlpbv1hBO6TRH2nohJmlTdUkkLefsPfTQQ83HgwFjX73CnoiICNCqjfSrxWVVNISdwp50Gl+GPefcbGB2YWHhzV7XIhJtTfvsJQWMoqKi5uOR1TgV9kRERIBWbaRflW6MLM5yyiCFPekcGsYpEuOahmoGA63frkkKeyIiInFl3rqdnJTTjV7dUrwuReKEwp5IjGuasxc0o7i4mOLiYiAyh09hT0REJKJlG+lHobCjZP0upg7r7XUpEkd8OYxTJJE0Bbpg0LjllluAyFCVpKA1D/EUERFJdC3bSD9aXrGbPQcamDq0l9elSBxRz55IjGs5Z6+lYCBAWGFPREQkLry/dgcAUxT2pBP5MuyZ2UwzK66urva6FJGoC3WwqXrQUM+eiIhInJi3bieDemXQPzvd61Ikjvgy7DnnZjvnirKzs70uRSTqmodx2qE9e5qzJyIi4n/hsGP++p0awimdzpdhTySRNLSYs9eSVuMUERGJD6u37WFXbb2GcEqnU9gTiXGhDubsBQJaoEVERCQezFsXma83dahW4pTOpbAnEuOae/YCh/bsNe3BJyIiIv71wbqd9M9OY2AvzdeTzqWwJxLjwi3m7DnncO5g+GsIhb0sTUREJGa0bCP9xDnHB+t2MmVoL6zN/HyRE6WwJxLjOurZC2rOnoiIiO+t31FLZc0BDeGUqFDYE4lxobAjGLBDPu1LChghH36CKSKtmdlFZrbSzNaY2V3tPH+dmS1u/O89M5voRZ0iEh1N8/W0OItEgy/DnvbZk0TS0Bj2AAoKCigoKAAiC7SoZ0/E38wsCDwAXAyMAa4xszFtTlsHnO2cmwD8B1DctVWK+EPLNtJPPli7kz6ZKZyU083rUiQOJXldwPFwzs0GZhcWFt7sdS0i0RZ2rnmPvQULFjQfT9JqnCLxYAqwxjm3FsDMngQuB5Y1neCce6/F+e8D+V1aoYhPtGwj/UTz9SSafNmzJ5JIGkLukG0XIDJnz7mDC7iIiC8NADa1eFzWeKwjXwL+3tGTZlZkZiVmVlJZWdlJJYpItCzZXM3mqn1MO6mP16VInFLYE4lxoXD4kA3VgebePs3bE/G19j7Kb/dNbWYziIS9Ozu6mHOu2DlX6JwrzMnJ6aQSRSRaHnl3Hd1Sglw+Kc/rUiROKeyJxLiGcAc9e40BUPP2RHytDBjY4nE+UN72JDObAPweuNw5t6OLahORKKqsOcCLiyq4siCf7mnJXpcjcUphTyTGhZ0j0M44/uaePYU9ET+bD4wws6FmlgJcDcxqeYKZDQKeA77gnFvlQY0iEgWPf7CRulCY66cP8boUiWO+XKBFJJEcbs4eoEVaRHzMOddgZrcBLwNB4BHn3FIzu7Xx+QeBHwC9gd82LuDQ4Jwr9KpmETlxdQ1h/vLBBs4ZlcNJOZlelyNxTGFPJMaFwq55yObNNx9cgLYpAGqBFhF/c87NAea0OfZgi6+/DHy5q+sS8ZuWbWSsm/NRBZU1B7hRvXoSZQp7IjEuMmcvMuK6uPjg9lrq2RMRETmoZRsZ6/743nqG9enGWSO0kJJEl+bsicS4kDu4qXpLwcYAqDl7IiIi/rFg4y4WbarixtOHEGinfRfpTAp7IjEuFDq4qXppaSmlpaXAwWGc2npBRESkdRsZq7bvOcB3n/uIrLQkPj053+tyJAFoGKdIjGsIH+zZKyyMrMngnGv+NDAUUtgTERFp2UbGom2793Pt7z+gbFctf7jhVDJT9Wu4RJ8ve/bMbKaZFVdXV3tdikjUhcJhktrZVD2pec5euKtLEhERkWNQXrWPzz40l4qqffzpi1M4fXgfr0uSBOHLsOecm+2cK8rOzva6FJGoCzk6mLPXuBpnjH6CKSIiIrC/PsQ1D7/Pjj11PPalqUwd1tvrkiSB+DLsiSSSUDjcPGevJa3GKSIiEvvWbd/Lhh213HPZWAoG9/S6HEkwCnsiMa4h1NFqnI1z9hT2REREYlZF9T4AhuV087gSSUQKeyIxLhR27c7Za+rtU9gTERGJXeVV+wHIy073uBJJRAp7IjEuss/eoW/VYFDDOEVERGJdRfU+ggEjJyvV61IkAWnNV5EYFwo7mjr2SkpKmo83rcYZVtgTERFp1UbGkorq/fTLSm13SoZItCnsicS4yJy9SM9eQUFB8/GmYZzq2RMREWndRsaSiqr99O+hIZziDQ3jFIlxobBr7sVrSQu0iIiIxL6K6n30z07zugxJUAp7IjEu5Fzz/LyioiKKiooAmhdtUdgTERFp3UbGCuccFdX7FfbEMwp7IjEuMmcvEuwefvhhHn74YQACWo1TRESkWcs2Mlbsqq3nQEOY/lqJUzyisCcS4xrC4XaHcSY1zuPTnD0REZHYVF4V2WMvr4d69sQbCnsiMS6kTdVFRER8qaI6ssdernr2xCMKeyIxLuQ62FRdYU9ERCRm1OyvP+TYlurGnj3N2ROPKOyJxLhQ2DXPz2upOew5hT0REREvbdxRy+T/eJW3V1e2Ol5evZ/koNEnUxuqizcU9kRiXMMRt14Id3VJIiIi0sL89TupDznmrdvZ6nhF1T76dU8joA3VxSMxtam6mV0BXAL0BR5wzr3ibUUi3gu12FR98uTJzcebAmBDSD17IiIiLdvIrvbR5moAlpXvbnW8XNsuiMeiHvbM7BHgUmCbc25ci+MXAb8GgsDvnXM/d849DzxvZj2BXwEKe5LwWs7ZKy0tbT7e1LMX1jBOERGRVm1kV1vSFPYqWoe9LdX7mTSwhwcViUR0xTDOR4GLWh4wsyDwAHAxMAa4xszGtDjle43PiyS8hiPM2dPWCyIiIt4JhR1Ly3eTlhygono/O/fWARAOO7ZU76e/tl0QD0U97Dnn3gJ2tjk8BVjjnFvrnKsDngQut4hfAH93zi1o73pmVmRmJWZWUllZ2d4pInEldMQ5ewp7IiIiXvm4cg/76kNcMj4PgOWNvXs79tZRFwrTv7vCnnjHqwVaBgCbWjwuazz2NeA84Eozu7W9Fzrnip1zhc65wpycnOhXKuIh5xyh8MF99swMa+zlS1LYExERadayjexKi8siQzg/d+pA4OC8vYrGbRf699Aee+IdrxZoae+d6JxzvwF+09XFiMSqlVtrAOjXzqeCAYU9ERERzy3ZXE1GSpCCwT3pn53WPG+vaUP1PG2oLh7yqmevDBjY4nE+UH60LzazmWZWXF1d3emFicSSlxZXEDC4YGy/Q55L0pw9ERERz320uZqxed0JBowx/bsf7NmraurZ0zBO8Y5XYW8+MMLMhppZCnA1MOtoX+ycm+2cK8rOzo5agSJec87x0uIKpp3Uu93NWDVnT0RExFsNoTBLy6sZNyDyO+mYvO6sqdzD/voQFdX7SQkG6JWR4nGVksiiHvbM7AlgLjDKzMrM7EvOuQbgNuBlYDnwtHNuabRrEfGTZRW7Wbt9L5dOyGv3+aAp7ImIiHjp48q97K8PMyG/Mez1704o7Fi9dQ/l1fvJzdaG6uKtqM/Zc85d08HxOcCc47mmmc0EZg4fPvxEShOJaS8triAYMC4cm9vu8+rZExER8dbisioAxrfo2QNYVlHNlup92lBdPOfVMM4TomGcEu+cc7y4uILpJ/WmV7f2h3+YGQFT2BMREfHKks3VdEsJMrRPJgADe2aQmZrEsvLdlFftJ08rcYrHvFqNMyY45zxZolfkSJZs3s3GnbXcNqN17/VDDz3U6nFSIKAFWkRERDi0jewKkcVZsptH2wQCxsn9s/hoczVbd0eGcYp4KaHD3t8+3MyvXl7JSX0zOSknk5P6ZnLKwB6M6d9d46vFUy8uLicpYIeswllUVNTqcTBghMLhrixNREQkJrVtI6OtIRRmWcVurp0yuNXxMf2785cPNhIKO/IU9sRjvgx7nTVnLzc7janDevNx5R7+WrKJvXUhAPpkpnL2yBymDO1JXchRs7+e3fsa6JGRzNi87ozp353e7ayOKNIZmoZwnjGiDz2OsIJXTlZq8z4+IiIi0nUiq24eXJylyZi87s1TLPprjz3xmC/DnnNuNjC7sLDw5hO5zvST+jD9pD5N16Siej9zP97Bm6sqeX3FVp5dUNZ8bnLQqA8dHC6X2z2NCfnZTBrUg0kDI/9lpPjydkqMWVRWzeaqfXzj/JGHPFdcXAwc/PRyZL9MVjVuvC4iIpLI2raR0ba4LLLfc9O2C03G9D/4WMM4xWtKJ43MjLwe6XymIJ/PFOQTCjvKdtWSnhKke1oyaclBqmrrWFa+m2UVu/loczWLNlXxyrKtAKQmBThzRA4XjO3HuaP7qudPjkl9KMx7H+/gxUXl/GPpFlKTApw/5tCN1G+55RagZdjL4s2VldQ1hElJ8uV6SyIiIp2ibRsZbU2Lswzr063V8RH9MhunWTgt0CKeU9jrQDBgDO7d+s3bIyOF6cP7MH14n+Zju/bWsXBTFf9aVcmry7by2vKtBAymDO3FRWNzuXBcLtnpyXy4sYp563ayrGI3A3tmMHFgNhPyezC4V4bmBya4/fUhzv3vf7G5ah9ZqUlcMDaX604bRHZ68hFfO7JfFg1hx/odexnZL6sLqhURERGADzdWMT4/+5Df49KSg4zom8m67XvpmXHktlwkmnwZ9mJpn72e3VKYMbovM0b35Z6ZY1havpuXl27hH0u28MPZy/jh7GXNn+6YwdDe3XhrVSWPvBtZVKNvViozJ+ZxxaQBjBvQHedg3Y69LC6rImDGJ8f3JzmoHpt4tnFnLZur9nHHuSP4yjknkZYcPOrXNgW8lVtqFPZERES6SM3+epaWVx+yanaTqUN7kZYc1Krv4jlfhr3OmrPX2cyMcQOyGTcgm3+7YBRrtu3hlWVbqD0QomBITwoG96R7WjINoTCrtu5hcVkVr6/YxmNz1/OHd9aR3zOd6tp6ag40NF/zv19ZxdfPG8HlkwY0L+sr8WXTzloAzhmVc0xBD2BYTjcCBqs1b09ERKTLLNhYRdjBlKG9233+e5eO0T64EhN8Gfb8YnjfTIb3PfQTn6RggDF53RmT152rpwyiuraeOUsq+OeKbfTrnsqE/B5MzO/B5qpa/vuVVXzz6UX89s2POffkvgzPyWREvyyG980kM1V/ffFgY2PYG9Qr45hfm5YcZEifbqxU2BMREeky89btIClgTB7co93nk4MBjvHzW5GoUFqIAdkZyVwzZRDXTBnU6vio3CzOGdmXl5du4cF/fcwf31lPXejgnmpD+3RjTF53xuZ1Z2DPDPpkppKTlUr/7DS6KQj6xsadtWSkBOnV7fDbLHRkZN8srcgpIiLSheat28m4AdlaiV1inn5CY1wgYFw8vj8Xj+9PQyjMxp21rNm2hxVbalhaHlkR9KXFFa1ekxw0LhibyzWnDmL6Sb21AEyM27SzlkG9Mo57XP/I3CxeWbaF/fWhYx4GKiIiIsdmf32IRZuqufH0IV6XInJEvgx7sbRAS1dKCgYYlpPJsJxMLhib23y8el89W6r3s33PAbbvOcCHG6v424ebeWlxBYN6ZXBVQT6fLshngJb/jUmbdu5jUO+jG8Lp3KHj/0f2yyTs4OPKPYzNy27nVSIiIvGvvTYyGhZtqqIuFGbKkF5d8v1EToQvw16sLtDilez0ZLLTkxlFZDXGyycN4K6LR/Py0i08OW8T//3qKu59bRWnn9SHSyf0Z1CvDPp2TyUnK43uaUlaKcpDzjk27qzljBF9jnxyB0Y1rsK5amuNwp6IiEiUzVu3EzM4VWFPfMCXYU+OLC05yOWTBnD5pAFs2lnLcws288yCTdz13EetzuuTmcLYvGzGDejOuLzISqL5PdMVALvI9j117KsPMbDn8fe6DunTjeSgsWrrnk6sTERERNozb/1ORvXLIlt76IkPKOwlgIG9MrjjvBF87RPDWbdjL1t376ey5gBbd+9n1dY9LNlczTtrtjcvEdwzI5lxA7IZPyCbSQN7MGlQD/pmpXn8p4hPzStxHuUwzoKCAgBKS0ubjyUHAwzrk8mqLVqkRUREEld7bWRnawiFKd2wiysL8qP2PUQ6k8JeAgkEjJNyMjkpJ/OQ5/bXh1ixpYYlm6tZsrmajzZXU/zWWhoaA2DfrFS6pSaRFDCSgwFG52Zx4+lDmJDfo4v/FPGlbNexbbuwYMGCdo+P6JfJwk1VnVWWiIiI73TURnampeW7qa0LMWWohnCKPyjsCRAZ9jlpYA8mDezRfGx/fYil5dV8uLGKFVtqONAQpiEUpq4hzCvLtvLch5spHNyTm84YykVjc7Xq53HYuCMS9vJ7Hvseey2N6pfFi4sr2HugQdtuiIiIdJJVW2vYXx9q/nB7/vqdAFqcRXxDvxVKh9KSgxQM7kXB4EP/QavZX89fS8p49L31/L//W8C4Ad35/iVjmDqstweV+tfGnbX0zUo94S0TRjQu0rJ6255WgV1ERESO33eeWcyisiqKzhzGv10wig/W7WRI7wz6dtf0FvEHX4a9RN16IZZkpSVz0xlDuWH6EGYvKucX/1jB54rf5+JxuVwzZRBmRIaAOhjYK53BvbuRHAx4XXbM2di4x96JGpV7cEVOhT0REZET55zj48o99MlM5aG31vLux9vZuKOWi8blHvnFIjHCl2FPWy/EjmDAuOKUAVw4NpeH317L7978mL8v2XLIeUkBY3DvDGaM6st3LhpNSpKCH0DZrn1M7YRx/4N6ZZCaFNAiLSIiIp1kV209Nfsb+Pp5I8nvmc6dzy5m9/4GpgzVKCbxD1+GPYk96SlBbj93BNdMGcTHlXtIChjBgBF2sHHnXlZv3cOKLTX8/p11LKvYzYNfKKB7WmIvWVzXEKa8eh8DO6FnL9i4+M6qbdp+QUREpDOs274XgCG9Mzj35H5MzO/BswvKuGR8f48rEzl6CnvSqXKyUsnJSm11rGBwz+avnykt465nF3PV7+byxy+eSl6P499fzu82V+3DOY4p7N18c8ed2aNys5j78Y7OKE1ERMR3DtdGHo8NOxrDXp9uAORmp/HVGZpCJP6isCdd6sqCfPpnp3Hrn0v51G/f5ZLxeeT1SKN/djp9MlNISQqQkhQgIyWJIb0z4npz9+Y99o4h7BUXF3f43KjcLP724WbG3fMy/bqnkpudxpfPHMaMUX1PuFYREZFYd7g28nis376XgMHAE1wxW8RLCnvS5U4f3odnvjKd7zyziCfnb6S2LtTueWeNzOHXn5tEz24pXVxh19h0HGHvcK4+dSABg/Kq/WzdvZ+5a3dQ/K+1CnsiIiLHYf2OWgb0TNc6A+JrCnviiVG5Wbxw2xk459i9r4Hy6n3s3FtHXUOYAw1h1m7fw32vrubS/32H3143mYlxuMLkpp21pCQF6Ntm2OvhlJaWAlBQUHDIcz0yUig666Tmx//54jIee38D++tDJ7y1g4iISKw7XBt5PDbs2MuQ3t065VoiXlHYE0+ZGdkZyWRnHLpYy+kn9eH//d8CrnpwLl88fQgNYce2mgPs3HuA04b25vrpQ8hO9+8iLxt31pLfM/2YNqMvLCwEIstBH8lpw3rz+3fWsXBTFadp/0MREYlzx9JGHolzjnXb93LZpLwTvpaIl3zZL21mM82suLq62utSJIomDuzBi187g+nDe/PQW2t5/IONLC6roqq2nv9+dRVn/Pyf/OrllezcW+d1qcels/bY68ipQ3sRMLRoi4iIyDGqqq1n9/4G9eyJ7/myZ0/77CWOnt1SePSLU6itayA9Odi8YMvS8moeeGMND7y5hsfmrueRG0+lcMiJ71fXlTbtrG21Umlny05PZmxeNnPX7uAbUfsuIiIi8Wdd00qcCnvic77s2ZPEk5GS1GplzrF52fz2ugJe/vpZ9MlM5fN/+IB/rar0sMJjU934iWE0e/YApp3Um4Ubq9hf3/4iOCLiPTO7yMxWmtkaM7urnedHm9lcMztgZt/yokaRRNN22wURv1LYE18b2S+Lp2+dxrA+mXz5T/N5aXEF1bX1PF2yiesfmccpP36Fmf/7Dnc8+SG/fm01aytjY9Pxpm0X8qO8nPNpw3pRFwqzYMOuqH4fETk+ZhYEHgAuBsYA15jZmDan7QRuB37VxeWJJKx122sj2y70Stz9gCU+KOyJ7/XJTOWJotOYNLAHtz2xgMKfvMp3nlnMuu17OH9MP3pkJFOyfhf3vb6Kyx94l3nrdnpd8nHtsXc8Th0Smbf3/lrN2xOJUVOANc65tc65OuBJ4PKWJzjntjnn5gP1XhQokog27NhLXo90UpO0mrX4my/n7Im0lZ2ezGM3TeVXr6wkYHDphDwm5Ge3GvpZtquW6x+Zxxf+8AH3XzuZ88f086zeTbsiYS/anxhmpSUzfkBk3p6IxKQBwKYWj8uAqcd7MTMrAooABg0adGKViSSw9TtqNV9P4oLCnsSN9JQg37+07eing/J7ZvDMrdP54h/nccufS/jBpWOYPLgnATOCAWNon25dsh/d/voQLy/dQp/MVLLSjm3riJKSkmP+fqed1JtH3lnHvroQ6Sn6hFIkxrS398pxrxvvnCsGigEKCwtPfP15ER85njayI+u372XmxP6ddj0RryjsSULp1S2Fx28+jVv/UsoPZy9r9dyAHun8+upJUV3VMxx2/NtfF/Hhxip+c80px/z649ko9rRhvXnoX2sp3bCLM0b0OebXi0hUlQEDWzzOB8o9qkXE1zprM/Wq2jqq99WrZ0/igsKeJJxuqUk8cuOpzFu3k311IULOUVvXwP+8uprPPjSXr31iBF/7xHCSgp0/pfVnf1/OS4sr+O4nR3PZxK7ZqPXUIb0IBoy5a7cr7InEnvnACDMbCmwGrgau9bYkkcS2bntkJc7BCnsSBxT2JCElBwOcPrx18Dnv5H7c88JSfv36at5cuY1PjO7HSX27cVJOJiflZJKSdPjwt78+xF/e38Anx/cnr8ehc/EeeWcdD7+9jhunD+HmM4cdV91FRUUAFBcXH/VrMlOTmJCfzftrvV+YRkRac841mNltwMtAEHjEObfUzG5tfP5BM8sFSoDuQNjMvg6Mcc7t9qpukVh0PG1kezbsiMyrH9onuouoiXQFc86/Q/oLCwtdZ47PFgF4YeFm7n11FRt31tL09sjLTuMb54/k05PzCQYOnWLjXGR45nMLNtMzI5l7PzeJGaP6AlCzv56f/X0Fj3+wkYvG5vLAdZPbvcbRaFpw5ljft7/4xwoefmsti+65gG6p+oxH/MfMSp1zhV7X4SdqIyXRHG8b2dZ9r63i16+vZvmPL+qSufwiJ+pwbaQvf+szs5nAzOHDh3tdisShyycN4PJJA9hXF2Ld9r2s3lbDI++u59vPLObht9dy50Wj+cTovq1W+vzz+xt4bsFmvnDaYOav38kX/zif22YM55RBPfje80vYuns/N585lH+7YNRxB70TcdaIHH735se8ubKSSyZowrmIiEhH1m/fS152uoKexAVfhj3n3GxgdmFh4c1e1yLxKz0lyJi87ozJ685lE/P4+5It/PLllXzpTyWcOaIPP7xsLCflZFKyfic/nr2Mc0f35UeXjaUuFOaeF5Zy/xtrABjRN5PffmU6pwzq6dmfZcrQXvTJTOXFxeUKeyIiIoexfkctQzSEU+KEL8OeSFczMz45vj/nj+nHX97fwL2vrOKi+97ihmlDeGFROQN7ZXDv5yYRCBhpgSC/uHICp4/ow+Zd+7jpjCGeb8oaDBifHJ/LU/M3sedAA5kayikiItKu9Tv2csl4fTAq8aHzlxsUiWPJwQBfPH0o//zWOVw+aQC/f2cdew808ODnC8hOb71n3mUT8/jKOSd5HvSaXDohjwMNYV5fvtXrUkRERGJSVW0dVbXadkHihz7eFzkOOVmp/OqqidwwbQhmMCo3y+uSjqhwcE/6dU/lxcUVXD5pgNfliIiIxJz1jStxDumjsCfxQWFP5ASMz8/u0u83efLk435tIBAZivp/729k9/56uqclH/lFIiIiPnEibWSTd1ZXAjA2r/sJX0skFmgYp4iPlJaWUlpaetyvv3RCHnWhMK8t01BOERGJLyfaRjrneG7BZqYO7dXufrkifqSwJ5JAJg/qwYAe6by4uMLrUkRERGLKorJq1m7fy2cm53tdikinUdgTSSBmxiUT+vP26kqqa+u9LkdERCRmPLegjNSkABePz/W6FJFOo7An4iNm1moz9+Nxyfj+1IccLy/d0klViYiIeO9E2si6hjCzFpVzwdhcsjSnXeKIwp5IgpmQn82gXhnMWlTudSkiIiIx4c2V26iqrefTp2i1aokvCnsiCcbM+NQpA3j34+2UV+3zuhwRERHPPbdgM30yUzhzRB+vSxHpVAp7IgnoM5PzcQ7+9uFmr0sRERHxVFVtHa+v2MplEweQFNSvxhJf9BMtkoAG9c5gytBePFtahnPO63JEREQ88+LiCupDjk9P1hBOiT8KeyIJ6sqCfNZu38uCjVVelyIiIuKJUNjx+AcbGdkvUxupS1xS2BNJUJ8c35/05CDPLijzuhQRERFP/OX9DSyr2M1XZww/4dWuRWJRktcFNDGzYcC/A9nOuSu9rkckFj300EOddq3M1CQuHpfL7EXl/ODSMaQlBzvt2iIiIl3tWNvILdX7+eXLKzlzRB8um5gXpapEvBXVsGdmjwCXAtucc+NaHL8I+DUQBH7vnPu5c24t8CUzeyaaNYn4WVFRUade7zMF+Tz34WZeXbaVmWroRETEx461jbxn1hLqQ2F+csV49epJ3Ir2MM5HgYtaHjCzIPAAcDEwBrjGzMZEuQ4Race0Yb3Jy07jmVIN5RQRkcTxytItvLx0K3ecN4JBvTO8LkckaqIa9pxzbwE72xyeAqxxzq11ztUBTwKXH+01zazIzErMrKSysrITqxWJfcXFxRQXF3fa9QIB49OT83l7dSX/XLG1064rIiLS1Y62jdxzoIF7Zi1ldG4WN585rAsqE/GOFwu0DAA2tXhcBgwws95m9iBwipnd3dGLnXPFzrlC51xhTk5OtGsViSm33HILt9xyS6de8/ppgzkpJ5ObHi3h9ic+ZPueA516fRERka5wtG3kP5ZsoaJ6Pz+6bCzJ2ldP4pwXP+HtDYp2zrkdzrlbnXMnOed+1uVViSSovt3TePH2M/jGeSP5x5ItnHfvv3hl6RavyxIREYmKFRW7SU0KUDikl9eliESdF2GvDBjY4nE+UH4sFzCzmWZWXF1d3amFiSSq1KQgd5w3gjl3nMGAHul88+lFbNu93+uyREREOt3KrTWM6JdJMKBFWST+eRH25gMjzGyomaUAVwOzjuUCzrnZzrmi7OzsqBQokqiG983igWsnU9cQ5qdzlntdjoiISKdbuaWGUf20gbokhqiGPTN7ApgLjDKzMjP7knOuAbgNeBlYDjztnFsazTpE5OgN6dONW84exvMLy/lg7Q6vyxEREek0u/bWsa3mAKNyM70uRaRLRHs1zmucc/2dc8nOuXzn3B8aj89xzo1snJ/3k2jWICLH7v+dM5wBPdL5wQtLqQ+FvS5HRESkU6zaWgPAyH5ZHlci0jV8uQSR5uyJRFd6SpAfzBzDyq01PDZ3g9fliIiIdIqmsDcqV2FPEkOS1wUcD+fcbGB2YWHhzV7XItKVnHNd9r0uGNOPs0fm8D+vrqKqto7Rud0Z3T+LIb27aVK7iIjEnKNpI1dsqSErLYnc7mldUJGI93wZ9kQk+syM/7h8HF99fAG/ffNjQuFIIzqibyb3XztZn4qKiIjvrNpaw+jcLMz0oaUkBl+GPTObCcwcPny416WIxLVBvTOY/bUz2F8fYs22PXy0uZp7X13FZfe/w48vH8tnCweqwRQREV9wzrFySw0zJ+Z5XYpIl/HlnD1tvSCJqqCggIKCgi7/vmnJQcYNyOaaKYOYc/uZnDqkF3c++xHfeGohtXUNXV6PiIhIW0dqI7fuPsDu/Q0amSIJxZc9eyKJasGCBV6XQE5WKn+6aQoPvLGG+15bxaZd+3jkhlPJzkj2ujQREUlgR2ojV2zZDWglTkksvuzZExFvBQPG7eeO4P5rJ7O4rIrPFc9lW81+r8sSERHpUPNKnAp7kkAU9kTkuH1yfH8eufFUNuyo5bMPzmXTzlqvSxIREWnXyi176JuVSs9uKV6XItJlfBn2tM+eSOw4c0QOf/nyVHburePKB99rHiYjIiISS1ZtrdF8PUk4vgx7WqBFJLYUDO7J07dOA+CqB+cyb91OjysSERE5KBR2rNpao/l6knB8GfZEJPaMzu3Os1+ZTk5WKp//wwe8vHSL1yWJiIgAsHFnLQcawpqvJwlHq3GK+MjNN9/sdQmHld8zg2dunc5Nj87nK38p5YbpQ/jqjOH0yUz1ujQREYlzh2sjV26JLM4yUsM4JcEo7In4SHFxsdclHFGvbik8fvNU/uPFZfzpvfU8PX8TXz5zGF8+cyhZaa23Z3DO8fu31zFv/U6+f8kYBvXO8KhqERHxu8O1kU0rcY7sl9lV5YjEBF8O49QCLSKxLSMliZ99egKvfONszh6Vw69fX805v3yTJ+ZtJBR2AOw90MBXH1/AT+Ys540V2/jkb97mmdIynHMeVy8iIvFm5ZYaBvXKICNF/RySWHwZ9rRAiySq0tJSSktLvS7jqA3vm8lvryvgha+ezrCcbtz93EfM/N93mLWonE/99l3+sWQL3/3kaN789jmMyevOt/66iK8+voDq2nqvSxcREZ85XBu5fMtu9epJQtLHGyI+UlhYCOC73q+JA3vw9C3TeHFxBT+bs5zbn/iQnhnJ/PlLUzl9eB8Anrj5NIrfWsu9r67k421z+fOXptC3e5rHlYuIiF901EZu3FHL2sq9XDtlkBdliXhKYU9EuoSZMXNiHued3I8XFm7mzJE5DOiR3vx8MGB85ZyTmJifzZcfK+HKB+fyf1+eysBemscnIiLHr2l16AvH5npciUjX8+UwThHxr/SUIFdPGdQq6LU0fXgfHr/5NHbvr+czv3uveVK9iIjI8Xhl2RZO7t9dHx5KQlLPnojEnEkDe/BU0TS+8IcPuOB/3iI1KUBmahKZaUn0yUwlNzuNvOw0RvbL4lOnDCApqM+tRETkUJU1ByjZsIs7zh3hdSkinvBl2DOzmcDM4cOHe12KiETJqNws/vbV03n+w83s3lfPngMN1OxvoLLmAMvKd/Pasq0caAjz15Iy/ufqSR32FIqISOJ6bflWnIMLxmgIpyQmX4Y959xsYHZhYWFs7zAtIidkQI90vjqj/Q91nHM8v3Az3/vbEj7567f5xWfGc9G4/l1coYiIxLJXlm5hYK90Tu6vzdQlMfky7ImImBmfOiWfUwb25I4nP+TWvyxgZL9M+malkZOVyqBeGdwwfQi9uqUc8lrnHGbmQdUiItJVavbX8+6aHVw/bbD+zZeEpbAn4iMlJSVelxBzhvTpxl9vnc7Db69l0aYqKvccYN26vbywcDOPvreeb104imunDCJgULJhF8VvreVfKyspGNyTi8blcsHYfvTP1hBQERG/a9tGvrmykrpQmAvHaQinJC7z235dLRUWFjr98isi7Vm1tYZ7XljK3LU7GNO/O8lJARZtqqJHRjIXjOnHgo1VrNm2B4DCwT353KkDuWRCfzJS9BlYLDKzUudcodd1+InaSEl0tz2+gLkf72Dev59HMKCePYlfh2sj9VuNiMSlkf2yePzmqbz0UQU///sKkoMB/uOKcVw5OZ/0lCAAa7bt4eWlW3h2QRnffmYxP5q9jIvG5dItJcj++jAHGkKMzcvmpjOG6hcFEREfOdAQ4s2VlVw6ob/+/ZaEprAn4iNFRUUAFBcXe1yJP5gZl07I49IJee0+P7xvJsP7Duf/nXMSJRt28eS8TbyydAtmRlpygKRAgOcXlvPa8q3cd/UkDfcUEYlhLdvI9z7ewZ4DDdpIXRKehnGK+EjTBHM/v2/95tnSMr7/whJSkwL815UTOe/kvq0m+u+vD/HhxiqWVezm3NF9GdKnm4fVxi8N4zx2aiMl0bRsI7/zzCL+/tEWSr5/HqlJQY8rE4muuBvGqX32RKSrfKYgn1MG9eBrT3zIzY+VkJ4cJL9nOvk909lbF2LhpirqGsIA/Pzvy7np9KHc9onhZKUle1y5iEhiqmsI8/LSrZw/pp+CniQ8X4Y97bMnIl1pWE4mz/2/6Ty3YDMfb9vDpl21bNq5j6SgccO0wZw2rDdD+3Tjd29+TPHba3l2QRm3nn0SZ43MYXhOJoGA4Zxj1dY9vLFyG1t372fKkF5MO6k3PTIO3RpCRESO37sfb6d6Xz2XTNDeqyK+DHsiIl0tNSnINVMGHfacX141keunDeHHLy7lP19aDi8tp2dGMhPye7B6aw3l1fsbrxXgj++uxwxOzu1Ov+6pBANGMGB0S03i5NzujB3QnbF52WSnq4dQRORYvLS4gqy0JM4Y0cfrUkQ8p7AnItKJxudn8/Qt09i0cx8frNvBvHU7WVRWxfj8bG4/dwRnj8qhT2YqizZV8d7Hked37K2jIeQIO8eu2jqeW7C5+XqfGN2X737yZIb3zfTwTyUi4h8vL93CBWNyNYRTBIU9EZFOZ2YM6p3BoN4ZXFU4sN1zCof0onBIr3af27HnAEvLdzN//U4efXc9F973Fl84bTBfPH0IK7bUMPfjHcxfv5Ne3VI47+R+nHtyX/J7ZkTzjyQi4hs1+xu4VEM4RQCFPRFfmTx5stclSBfonZnKWSNzOGtkDjdMH8L/vLqKx+au59H31gOQlhxg8qCebK7axz2zlnLPrKUMy+lG36xUuqclk52eTMg5qmvrqdpXz766EEP7dGNkvyxG5WYypn82A3ult1pVFCL7Uh1oCJOVmnTIcyIisW7y5MmU7dpHdnoypw/XEE4RUNgT8ZXS0lKvS5Au1iczlZ98ajzXTxvC26srmZDfg4kDs5uHJ62t3MPry7cxf/1Oqmrr2bCjlup99QQDRo+MZHpkJJOVlsSS8mrmLKmgadeOXt1SmJifzch+WZTt2sfKrTWs276XUNiRFDB6ZKTQu1sKw3K6MTq3O6P7Z3HKwB707Z7m4d2IT2Z2EfBrIAj83jn38zbPW+PznwRqgRudcwu6vFCRGPfu+/M49T9f48Kx/UhJCnhdjkhMUNgTEfGBUblZjMrNOuT4sJxMhuVkcvNZw454jdq6BlZv3cOS8moWbapi4aYq3lq9nQE90hmVm8VFY3Ppnp5EVW09u2rrqaw5wPKK3fxj6Racg4DBmSNy+GzhQM4b0/eo58M459RT2AEzCwIPAOcDZcB8M5vlnFvW4rSLgRGN/00Fftf4fxFp4e3V26k50MAlE/K8LkUkZijsiYgkiIyUJCYO7MHEgT24bupgAMJhRyBw+CBWW9fAyi01vL58G88uKOOrjy8gKy2J/tlppCYFSU0KkJ2ezKDeGQzp3Y0BPdKpqN7HsordLKuooaq2jn99e0ZX/BH9aAqwxjm3FsDMngQuB1qGvcuBx5xzDnjfzHqYWX/nXEU0C/tw4y4ONO4hKeIHT87bSI+MZKaf1NvrUkRihsKeiI809Y64prF4IifoSEEPIiHxlEE9OWVQT75x/kjeXbOdOR9VUFVbT10ozIGGEJur9jF37Q5q60LNr8tOT+bk/llMHt2X+lCY5KCGVbVjALCpxeMyDu21a++cAUBUw97tT37Ipp37ovktRDrVhl9cCkDyD9RGijRR2BMRkaMWDFjz4jFtOeeo3HOAsl37yO2eRv/sNA3fPLL2blDb31SP5pzIiWZFQBHAoEGH3xfySO773CkcaAgd+USRGHH6L7yuQCT2+DLsmdlMYObw4cO9LkVERBqZGX2z0uibpUVcjkEZ0HJ/jnyg/DjOAcA5VwwUAxQWFp5Q90bB4J4n8nIREYkBvhxT45yb7Zwrys7O9roUERGREzEfGGFmQ80sBbgamNXmnFnA9RZxGlAd7fl6IiISH3zZsyciIhIPnHMNZnYb8DKRrRcecc4tNbNbG59/EJhDZNuFNUS2XviiV/WKiIi/KOyJiIh4yDk3h0iga3nswRZfO+CrXV2XiIj4ny+HcYqIiIiIiMjhqWdPxEceeughr0sQERGJSWojRQ6lsCfiI0VFRV6XICIiEpPURoocSsM4RURERERE4pDCnoiPFBcXU1xc7HUZIiIiMUdtpMihLLLIlz8VFha6kpISr8sQ6TJmBoCf37cix8PMSp1zhV7X4SdqIyXRqI2URHW4NlI9eyIiIiIiInFIYU9ERERERCQOKeyJiIiIiIjEIYU9ERERERGROKSwJyIiIiIiEocU9kREREREROKQr7deMLNKYMNxvLQPsL2Ty4kHui8d073pmO5N+3RfOnY892awcy4nGsXEq+NsI/Vz2zHdm47p3rRP96VjujftO9770mEb6euwd7zMrET7NR1K96Vjujcd071pn+5Lx3RvYpf+bjqme9Mx3Zv26b50TPemfdG4LxrGKSIiIiIiEocU9kREREREROJQooa9Yq8LiFG6Lx3TvemY7k37dF86pnsTu/R30zHdm47p3rRP96Vjujft6/T7kpBz9kREREREROJdovbsiYiIiIiIxDWFPRERERERkTiUUGHPzC4ys5VmtsbM7vK6Hi+Z2UAze8PMlpvZUjO7o/F4LzN71cxWN/6/p9e1esHMgmb2oZm92PhY9wUwsx5m9oyZrWj82ZmmewNm9o3G99ESM3vCzNIS9b6Y2SNmts3MlrQ41uG9MLO7G/9NXmlmF3pTtYDayCZqH49MbeSh1D52TG3kQV60kQkT9swsCDwAXAyMAa4xszHeVuWpBuDfnHMnA6cBX228H3cBrzvnRgCvNz5ORHcAy1s81n2J+DXwD+fcaGAikXuU0PfGzAYAtwOFzrlxQBC4msS9L48CF7U51u69aPw352pgbONrftv4b7V0MbWRrah9PDK1kYdS+9gOtZGHeJQubiMTJuwBU4A1zrm1zrk64Engco9r8oxzrsI5t6Dx6xoi/ygNIHJP/tR42p+AKzwp0ENmlg9cAvy+xWHdF7PuwFnAHwCcc3XOuSp0bwCSgHQzSwIygHIS9L44594CdrY53NG9uBx40jl3wDm3DlhD5N9q6XpqIxupfTw8tZGHUvt4RGojG3nRRiZS2BsAbGrxuKzxWMIzsyHAKcAHQD/nXAVEGjygr4eleeU+4DtAuMUx3RcYBlQCf2wcvvN7M+tGgt8b59xm4FfARqACqHbOvUKC35c2OroX+nc5dujvoh1qH9t1H2oj21L72AG1kUclqm1kIoU9a+dYwu87YWaZwLPA151zu72ux2tmdimwzTlX6nUtMSgJmAz8zjl3CrCXxBl20aHGsfWXA0OBPKCbmX3e26p8Q/8uxw79XbSh9vFQaiM7pPaxA2ojT0in/LucSGGvDBjY4nE+kW7khGVmyUQasv9zzj3XeHirmfVvfL4/sM2r+jxyOnCZma0nMozpE2b2F3RfIPIeKnPOfdD4+BkijVui35vzgHXOuUrnXD3wHDAd3ZeWOroX+nc5dujvogW1jx1SG9k+tY8dUxt5ZFFtIxMp7M0HRpjZUDNLITLhcZbHNXnGzIzI2PLlzrl7Wzw1C7ih8esbgBe6ujYvOefuds7lO+eGEPkZ+adz7vMk+H0BcM5tATaZ2ajGQ+cCy9C92QicZmYZje+rc4nM8Un0+9JSR/diFnC1maWa2VBgBDDPg/pEbWQztY8dUxvZPrWPh6U28sii2kaac4kzSsPMPklkrHkQeMQ59xNvK/KOmZ0BvA18xMFx998lMi/haWAQkTfoVc65thNJE4KZnQN8yzl3qZn1RvcFM5tEZFJ+CrAW+CKRD40S+t6Y2Y+AzxFZxe9D4MtAJgl4X8zsCeAcoA+wFbgHeJ4O7oWZ/TtwE5F793Xn3N+7vmoBtZFN1D4eHbWRral97JjayIO8aCMTKuyJiIiIiIgkikQaxikiIiIiIpIwFPZERERERETikMKeiIiIiIhIHFLYExERERERiUMKeyIiIiIiInFIYU/kOJlZyMwWmtlSM1tkZt80s8O+p8xsiJldG4Vavm5mGcdw/q1mdn1n1yEiIgJqI0VihbZeEDlOZrbHOZfZ+HVf4HHgXefcPYd5zTk07kvUybWsBwqdc9s787oiIiLHQ22kSGxQz55IJ3DObQOKgNssYoiZvW1mCxr/m9546s+BMxs/7fxGR+eZWX8ze6vxvCVmdmbj8QvMbG7juX81s0wzux3IA94wszfa1mZmPzezZWa22Mx+1Xjsh2b2LTPLa/weTf+FzGywmeWY2bNmNr/xv9O74j6KiEj8URsp4h317Ikcp5afWrY4tgsYDdQAYefcfjMbATzhnCts+6ll47CS9s77NyDNOfcTMwsCGUAq8BxwsXNur5ndCaQ6537c0aeWZtYLmAuMds45M+vhnKsysx8Ce5xzv2px7leBs51znzWzx4HfOufeMbNBwMvOuZM79w6KiEi8UhspEhuSvC5AJM5Y4/+TgfvNbBIQAkZ2cH5H580HHjGzZOB559xCMzsbGAO8a2YAKUQaqcPZDewHfm9mLwEvtlt05FPJLwNnNh46DxjT+H0AuptZlnOu5gjfT0REpCNqI0W6mMKeSCcxs2FEGqNtwD3AVmAikeHS+zt42TfaO88595aZnQVcAvzZzH4J7AJedc5dc7Q1OecazGwKcC5wNXAb8Ik2dfcH/gBc5pzb03g4AExzzu072u8lIiLSEbWRIt7QnD2RTmBmOcCDwP0uMjY6G6hwzoWBLwDBxlNrgKwWL233PDMbDGxzzj1MpJGZDLwPnG5mwxvPyTCzkR1ct6muTCDbOTcH+Dowqc3zycDTwJ3OuVUtnnqFSKPXdF6r14mIiBwttZEi3lHYEzl+6Y0TtpcCrxH5x/9Hjc/9FrjBzN4nMuxkb+PxxUCDRZah/sZhzjsHWGhmHwKfAX7tnKsEbgSeMLPFRBq20Y3nFwN/b2fyeRbwYuP5/yLyKWlL04FTgR+1mICeB9wOFDZOWF8G3Hqc90hERBKT2kiRGKAFWkREREREROKQevZERERERETikMKeiIiIiIhIHFLYExERERERiUMKeyIiIiIiInFIYU9ERERERCQOKeyJiIiIiIjEIYU9ERERERGROPT/Affwr5AG5nfsAAAAAElFTkSuQmCC\n", "text/plain": ["<Figure size 1080x504 with 2 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["plot_losses(errors, train_errors)"]}, {"cell_type": "markdown", "id": "competent-david", "metadata": {}, "source": ["Nous avons donc un double (sans jeu de mots) probl\u00e8me ici. Lorsque $X^TX$ n'est pas inversible, nous devons en choisir une parmi une infinit\u00e9 : c'est la r\u00e9gion \u00e0 gauche de la ligne vertical en pointill\u00e9. La solution $X^\\dagger\\boldsymbol{y}$ est celle de norme minimale, la pr\u00e9f\u00e9rable, mais le probl\u00e8me reste mal pos\u00e9. Lorsque $X^TX$ est presque inversible les performances de g\u00e9n\u00e9ralisation sont particuli\u00e8rement mauvaises.\n", "\n", "Un autre probl\u00e8me appara\u00eet. Lorsque $X^TX$ est presque inversible (i.e. son d\u00e9terminant est tr\u00e8s proche de $0$), son inverse est tr\u00e8s instable. De toutes petites perturbations de $X$ affectent tr\u00e8s significativement $(X^TX)^{-1}$. L'exemple suivant illustre ce probl\u00e8me. Consid\u00e9rons le syst\u00e8me d'\u00e9quations suivant :\n", "\n", "$$Ax=y$$"]}, {"cell_type": "code", "execution_count": 7, "id": "packed-porter", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Soit une matrice A=\n", " [[1.98 2.  ]\n", " [1.   1.01]]\n"]}], "source": ["A = np.array([[1.98, 2.], [1., 1.01]])\n", "print('Soit une matrice A=\\n', A)"]}, {"cell_type": "code", "execution_count": 8, "id": "defensive-mustang", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Nos donn\u00e9es sont x=\n", " [[1]\n", " [1]] \n", " et nos labels y=\n", " [[3.98]\n", " [2.01]]\n"]}], "source": ["x = np.array([[1], [1]])\n", "y = np.dot(A, x)\n", "print('Nos donn\u00e9es sont x=\\n', x, '\\n et nos labels y=\\n', y)"]}, {"cell_type": "markdown", "id": "binary-burns", "metadata": {}, "source": ["Imaginons maintenant (comme c'est le cas en machine learning) que nous n'observons que $A$ (la matrice qui contiendrait nos donn\u00e9es) et $y$ (les labels). Nous cherchons \u00e0 d\u00e9terminer l'inconnue $x$. C'est tr\u00e8s facile car ici tout est d\u00e9terministe et $A$ est bien inversible ($\\text{det}(A)\\neq 0$) :\n", "\n", "$$\\hat{x}=A^{-1}y$$"]}, {"cell_type": "code", "execution_count": 9, "id": "iraqi-gathering", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Notre pr\u00e9diction pour x, x_hat=\n", " [[1.]\n", " [1.]]\n"]}], "source": ["x_hat = np.dot(np.linalg.inv(A), y)\n", "print('Notre pr\u00e9diction pour x, x_hat=\\n', x_hat)"]}, {"cell_type": "markdown", "id": "muslim-phase", "metadata": {}, "source": ["Tout marche tr\u00e8s bien. Cependant, en pratique, nos donn\u00e9es ne sont que rarement aussi propres. Imaginons que notre collecte soit ent\u00e2ch\u00e9e d'un petit peu de bruit et arrondissons $y$."]}, {"cell_type": "code", "execution_count": 10, "id": "fiscal-caribbean", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Notre arrondi y_round=\n", " [[4.]\n", " [2.]] \n", " On remarque que l'\u00e9crat \u00e0 y est tr\u00e8s petit :\n", " [[ 0.02]\n", " [-0.01]]\n"]}], "source": ["y_round = np.round(y)\n", "print(\n", "    'Notre arrondi y_round=\\n', y_round, \n", "    '\\n On remarque que l\\'\u00e9crat \u00e0 y est tr\u00e8s petit :\\n', y_round-y\n", ")"]}, {"cell_type": "markdown", "id": "genuine-upset", "metadata": {}, "source": ["Calculons maintenant l'inconnue $x$ associ\u00e9e \u00e0 ces nouvelles observations."]}, {"cell_type": "code", "execution_count": 11, "id": "generic-guyana", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Notre pr\u00e9diction pour x, x_hat=\n", " [[-200.]\n", " [ 200.]]\n"]}], "source": ["x_hat = np.dot(np.linalg.inv(A), y_round)\n", "print('Notre pr\u00e9diction pour x, x_hat=\\n', x_hat)"]}, {"cell_type": "markdown", "id": "ancient-coach", "metadata": {}, "source": ["Le r\u00e9sultat est catastrophiquement mauvais. Une perturbation ridicule des $y$ a entra\u00een\u00e9 un effet de tr\u00e8s grande ampleur sur nos estimateurs $\\hat{x}$. Ce probl\u00e8me qui appara\u00eet dans l'effet double descente et ici est li\u00e9 au conditionnement de la matrice $X^TX$ (ici la matrice $A$). Son conditionnement est le ratio de sa plus grande valeur propre et de sa plus petite valeur propre. Elles sont ici :"]}, {"cell_type": "code", "execution_count": 13, "id": "spiritual-accident", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Le conditionnement donne : -44702.49997761842\n"]}], "source": ["eigenvalue = np.linalg.eig(A)[0]\n", "eigen_ratio = np.max(eigenvalue)/np.min(eigenvalue)\n", "print('Le conditionnement donne :', eigen_ratio)"]}, {"cell_type": "markdown", "id": "persistent-elevation", "metadata": {}, "source": ["La valeur semble d\u00e9raisonnablement grande lorsqu'on la compare aux valeurs de nos donn\u00e9es. L'id\u00e9e est ainsi d'accro\u00eetre les valeurs propres lors du calcul de l'inverse :\n", "\n", "$$X^+=(X^TX+\\lambda I)^{-1}X^T,$$\n", "\n", "o\u00f9 $X^+$ est une pseudo-inverse r\u00e9gularis\u00e9e. En rajoutant $\\lambda$ dans la diagonale, le ratio de la plus grande valeur propre avec la plus petite devient :\n", "\n", "$$\\frac{\\gamma_{\\text{max}}+\\lambda}{\\gamma_{\\text{min}}+\\lambda},$$\n", "\n", "o\u00f9 $\\gamma$ sont les dites valeurs propres. Reprenons notre exemple et calculons notre pseudo-inverse r\u00e9gularis\u00e9e :"]}, {"cell_type": "markdown", "id": "timely-productivity", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Proposez ci-dessous l'inverse r\u00e9gularis\u00e9e de $A$.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "id": "20292707", "metadata": {}, "source": ["I = np.eye(2)\n", "lambda_ = 0.1\n", "# on calcule notre r\u00e9gularisation et la pseudo inverse\n", "####### Complete this part ######## or die ####################\n", "...\n", "###############################################################\n", "\n", "x_hat = np.dot(A_inv_regularized, y_round)\n", "print('Notre pr\u00e9diction pour x, x_hat=\\n', x_hat)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "metropolitan-formation", "metadata": {}, "source": ["On retombe presque sur la valeur initiale qu'on aurait voulu obtenir. On constatera de plus que la valeur de la r\u00e9gularisation \"$0.1$\" est ridiculement faible.\n", "\n", "Nous avons certes pu obtenir une pseudo-inverse r\u00e9gularis\u00e9e, mais notre objectif reste de minimiser une erreur de pr\u00e9diction d'un mod\u00e8le. Quel est le lien entre ce pseudo-inverse r\u00e9gularis\u00e9 et notre probl\u00e8me intial ? Il se trouve que cela revient en fait \u00e0 r\u00e9soudre le probl\u00e8me d'optimisation suivant :\n", "\n", "$$\\text{argmin}_{\\beta\\in\\mathbb{R}^n}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2,\\text{ s.t. }\\lVert\\beta\\rVert_2\\leq c,$$\n", "\n", "pour une constante $c>0$. En passant au Lagragien, on obtient ainsi : \n", "\n", "$$\\text{argmin}_{\\beta\\in\\mathbb{R}^n}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2+\\lambda\\lVert\\beta\\rVert_2,$$\n", "pour $\\lambda>0$.\n", "\n", "Annulons le gradient afin de montrer que la solution de ce probl\u00e8me est-celle donn\u00e9e plus haut.\n", "\n", "$$\\nabla (\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2+\\lambda\\lVert\\beta\\rVert_2)=2X^TX\\beta-2X^Ty+2\\lambda\\beta=2(X^TX+\\lambda I)\\beta-2X^T \\boldsymbol{y},$$\n", "\n", "En annulant, on obtient : \n", "\n", "$$\\hat{\\beta}=(X^TX+\\lambda I)^{-1}X^T\\boldsymbol{y}=X^+\\boldsymbol{y}.$$\n", "Si $X^TX$ n'\u00e9tait pas inversible, $X^TX+\\lambda I$ l'est n\u00e9cessairement. On retrouve bien la m\u00eame solution. C'est bien ce probl\u00e8me des moindres carr\u00e9s r\u00e9gularis\u00e9s qu'on appelle Ridge. Reprenons maintenant l'effet double descente !"]}, {"cell_type": "markdown", "id": "centered-trustee", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Proposez ci-dessous la pseudo-inverse r\u00e9gularis\u00e9e de $X$.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "id": "2301f447", "metadata": {}, "source": ["d = 50\n", "redo = 50\n", "\n", "lambda_=0.1\n", "\n", "beta = np.random.uniform(-2, 2, size=(d, 1))\n", "\n", "mu = [0 for _ in range(d)]\n", "cov = np.diag([1 for _ in range(d)])\n", "\n", "test_size = 500\n", "X_test = np.random.multivariate_normal(mean=mu, cov=cov, size=test_size)\n", "y_test = np.dot(X_test, beta) + np.random.normal(0, 1, size=(test_size, 1))\n", "\n", "errors = []\n", "train_errors = []\n", "for m in range(1, 100):\n", "    error = 0\n", "    train_error = 0\n", "    for j in range(redo):\n", "        # dataset construction\n", "        X = np.random.multivariate_normal(mean=mu, cov=cov, size=m)\n", "        y = np.dot(X, beta) + np.random.normal(0, 1, size=(m, 1))\n", "        \n", "        # param estimation\n", "        ####### Complete this part ######## or die ####################\n", "        pseudo_reg_inv = ...\n", "        ###############################################################\n", "        \n", "        beta_pinv = np.dot(pseudo_reg_inv, y)\n", "        \n", "        # risk estimation\n", "        error += ((np.dot(X_test, beta_pinv)-y_test)**2).sum()/(test_size*redo)\n", "        train_error += ((np.dot(X, beta_pinv)-y)**2).sum()/(m*redo)\n", "    train_errors.append(train_error)\n", "    errors.append(error)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "33d312e3", "metadata": {}, "source": ["plot_losses(errors, train_errors)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "variable-dragon", "metadata": {}, "source": ["\n", "\n", "La r\u00e9gularisation en rendant notre probl\u00e8me beaucoup plus stable a permis de gommer cet effet double descente. L'inversion la matrice $X^TX+\\lambda I$ est beaucoup moins sensible aux bruits pr\u00e9sents dans la matrice $X$. Notre probl\u00e8me g\u00e9n\u00e9ralise mieux lorsque la taille du jeu de donn\u00e9es est faible voire critique (proche de la dimension)."]}, {"cell_type": "markdown", "id": "integrated-vehicle", "metadata": {}, "source": ["## II. Ridge et la *data augmentation*"]}, {"cell_type": "markdown", "id": "editorial-board", "metadata": {}, "source": ["Nous allons ici \u00e9tudier la *data augmentation* du point de vue de Ridge.\n", "\n", "Les probl\u00e8mes \u00e9voqu\u00e9s pr\u00e9c\u00e9demment peuvent se r\u00e9soudre assez facilement en augmentant le nombre d'invididus dans notre jeu d'apprentissage. En effet, le mauvais conditionnement de $X^TX$ vient du fait que les vecteurs lignes de $X$ ne sont pas g\u00e9n\u00e9rateurs (au sens de l'alg\u00e8bre) de l'espace $\\mathbb{R}^n$ ou, s'ils le sont, c'est via une composante orthogonale de taille tr\u00e8s r\u00e9duite. Plus le nombre d'individus dans $X$ devient important, plus il est probable qu'une forte composante dans chaque dimension de l'espace existe.  Cependant, lab\u00e9liser de nouvelles donn\u00e9es peut \u00eatre extr\u00eamement couteux en temps de travail. Une alternative est de cr\u00e9er des donn\u00e9es synth\u00e9tiques. Nous allons \u00e9tudiers quelques strat\u00e9gies.\n", "\n", "Consid\u00e9rons dans un premier temps le probl\u00e8me Ridge ci-dessous :"]}, {"cell_type": "code", "execution_count": 2, "id": "bearing-custody", "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": 3, "id": "cooked-cornwall", "metadata": {}, "outputs": [], "source": ["# on est en dimension 10\n", "n = 10\n", "\n", "noise = 1\n", "\n", "lambda_=2.\n", "\n", "beta = np.random.uniform(-2, 2, size=(n, 1))\n", "\n", "mu = [0 for _ in range(n)]\n", "cov = np.diag([1 for _ in range(n)])\n", "\n", "p = 100\n", "\n", "redo = 100"]}, {"cell_type": "code", "execution_count": 4, "id": "graphic-pointer", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["E[beta_est]=\n", " [[ 1.7917681 ]\n", " [-1.71988841]\n", " [-0.94560348]\n", " [-1.34890183]\n", " [-0.46855263]\n", " [-1.6530069 ]\n", " [ 1.80314769]\n", " [ 1.18201415]\n", " [ 0.40894296]\n", " [ 1.8488014 ]]\n"]}], "source": ["estimated_ridge_beta = np.zeros((n, 1))\n", "for j in range(redo):\n", "    X = np.random.multivariate_normal(mean=mu, cov=cov, size=p)\n", "    y = np.dot(X, beta) + np.random.normal(0, 1, size=(p, 1)) * noise\n", "\n", "    estimated_ridge_beta += np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)+lambda_*np.eye(n)), X.T), y)\n", "estimated_ridge_beta/=redo\n", "print('E[beta_est]=\\n', estimated_ridge_beta)"]}, {"cell_type": "markdown", "id": "powered-design", "metadata": {}, "source": ["### a. Rajouter une base de $\\mathbb{R}^n$ dans $X$"]}, {"cell_type": "markdown", "id": "interracial-massage", "metadata": {}, "source": ["Vu que le probl\u00e8me vient de l'absence ou du moins de la petite taille de certaines composantes de $\\mathbb{R}^n$ construites \u00e0 partir des vecteurs ligne de $N$, rajoutons dans $X$ des individus fictifs repr\u00e9sentants ces composantes :\n", "\n", "$$\\tilde{X}=\\begin{pmatrix}X\\\\\n", "\\sqrt{\\lambda}I_n\\end{pmatrix},\\text{ et }\\tilde{y}=\\begin{pmatrix}\\boldsymbol{y}\\\\0\\end{pmatrix}.$$\n", "\n", "Ici, $\\sqrt{\\lambda}I_n$ est une base orthogonale de $\\mathbb{R}^n$ dont la norme de chacun des vecteurs est $\\sqrt{\\lambda}$. Le label associ\u00e9 \u00e0 ces nouvelles donn\u00e9es est $0$. La solution du probl\u00e8me des moindres carr\u00e9s est donn\u00e9e par :\n", "\n", "$$\\tilde{\\beta}=(\\tilde{X}^T\\tilde{X})^{-1}\\tilde{X}^T\\tilde{y}.$$\n", "\n", "On v\u00e9rifie assez rapidement que $\\tilde{X}^T\\tilde{X}$ revient \u00e0 faire $X^TX+\\lambda I_n$ (les $\\sqrt{\\lambda}$ n'apparaisse que dans la diagonale et au carr\u00e9) et que $\\tilde{X}^T\\tilde{y}=X^T\\boldsymbol{y}$. Ainsi, $\\tilde{\\beta}=(X^TX+\\lambda I_n)^{-1}X^T\\boldsymbol{y}$ (les $\\sqrt{\\lambda}$ sont associ\u00e9s au label $0$). C'est la solution du probl\u00e8me des moindres carr\u00e9s avec une p\u00e9nalit\u00e9 $\\ell_2$ (Ridge) !\n", "\n", "La p\u00e9nalit\u00e9 revient \u00e0 nous garantir que les vecteurs lignes de $X$ \"remplissent\" bien les directions de l'espace $\\mathbb{R}^n$"]}, {"cell_type": "code", "execution_count": 5, "id": "wrapped-weekend", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["E[beta_est_2]=\n", " [[ 1.77866122]\n", " [-1.7203401 ]\n", " [-0.92701817]\n", " [-1.35138429]\n", " [-0.46404593]\n", " [-1.67993017]\n", " [ 1.82816509]\n", " [ 1.16022863]\n", " [ 0.40347003]\n", " [ 1.83440503]]\n", "Difference :\n", " [[0.01310687]\n", " [0.00045169]\n", " [0.01858532]\n", " [0.00248245]\n", " [0.0045067 ]\n", " [0.02692327]\n", " [0.0250174 ]\n", " [0.02178552]\n", " [0.00547293]\n", " [0.01439637]]\n"]}], "source": ["estimated_ridge_beta_2 = np.zeros((n, 1))\n", "\n", "for j in range(redo):\n", "    X = np.random.multivariate_normal(mean=mu, cov=cov, size=p)\n", "    y = np.dot(X, beta) + np.random.normal(0, 1, size=(p, 1)) * noise\n", "    \n", "    X_tilde = np.concatenate([X, np.eye(n)*np.sqrt(lambda_)], axis=0)\n", "    y_tilde = np.concatenate([y, np.zeros((n, 1))], axis=0)\n", "\n", "    estimated_ridge_beta_2 += np.dot(\n", "        np.dot(np.linalg.inv(np.dot(X_tilde.T, X_tilde)), X_tilde.T), y_tilde\n", "    )\n", "estimated_ridge_beta_2/=redo\n", "print('E[beta_est_2]=\\n', estimated_ridge_beta_2)\n", "print('Difference :\\n', np.abs(estimated_ridge_beta-estimated_ridge_beta_2))"]}, {"cell_type": "markdown", "id": "desirable-pasta", "metadata": {}, "source": ["\u00c7a marche !"]}, {"cell_type": "markdown", "id": "increasing-chain", "metadata": {}, "source": ["### b. Rajouter un bruit centr\u00e9 en $0$ de covariance $\\lambda I_n$"]}, {"cell_type": "markdown", "id": "removable-surname", "metadata": {}, "source": ["Soit $m\\in\\mathbb{N}^\\star$. Tirons $m$ vecteurs $x_r^{(i)}$ selon $\\mathcal{N}(0, \\lambda I_n)$. Soit la matrice $X_r$ construite comme suit : \n", "\n", "$$X_r=\\begin{pmatrix}{x_r^{(1)}}^T\\\\ \\vdots\\\\{x_r^{(i)}}^T\\\\ \\vdots\\\\{x_r^{(m)}}^T\\end{pmatrix}.$$\n", "\n", "Calculons maintenant $\\frac{1}{m}X_r^TX_r$. On remarque que dans la diagonales nous avons la somme de coordonn\u00e9es au carr\u00e9s : c'est un estimateur de la variance (i.e. $\\lambda$). Dans les autres cellules c'est la somme du produit de variables al\u00e9atoires ind\u00e9pendantes, c'est un estimateur de $0$. Nous avons donc : $\\frac{1}{m}X_r^TX_r=\\lambda I_n$. Il suffit alors de rajouter ces \u00e9chantillons \u00e0 notre matrice $X$ originale en les pond\u00e9rant avec $\\frac{1}{m}$ et en leur associant le label $0$ pour obtenir une approximation de Ridge."]}, {"cell_type": "code", "execution_count": 6, "id": "forbidden-singles", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["E[beta_est_3]=\n", " [[ 1.84117962]\n", " [-1.77560885]\n", " [-0.96625804]\n", " [-1.40936682]\n", " [-0.45807957]\n", " [-1.72162314]\n", " [ 1.87253104]\n", " [ 1.20700708]\n", " [ 0.43995201]\n", " [ 1.89570665]]\n", "Difference :\n", " [[0.04941152]\n", " [0.05572044]\n", " [0.02065456]\n", " [0.06046498]\n", " [0.01047306]\n", " [0.06861625]\n", " [0.06938335]\n", " [0.02499293]\n", " [0.03100905]\n", " [0.04690525]]\n"]}], "source": ["estimated_ridge_beta_3 = np.zeros((n, 1))\n", "\n", "mu_tilde = [0 for _ in range(n)]\n", "cov_tilde = np.diag([lambda_ for _ in range(n)])\n", "m=1000\n", "    \n", "for j in range(redo):\n", "    X = np.random.multivariate_normal(mean=mu, cov=cov, size=p)\n", "    y = np.dot(X, beta) + np.random.normal(0, 1, size=(p, 1)) * noise\n", "    \n", "\n", "    X_r = np.random.multivariate_normal(mean=mu_tilde, cov=cov_tilde, size=m)/m\n", "    y_r = np.zeros((m, 1))\n", "    \n", "    X_tilde = np.concatenate([X, X_r], axis=0)\n", "    y_tilde = np.concatenate([y, y_r], axis=0)\n", "\n", "    estimated_ridge_beta_3 += np.dot(\n", "        np.dot(np.linalg.inv(np.dot(X_tilde.T, X_tilde)), X_tilde.T), y_tilde\n", "    )\n", "estimated_ridge_beta_3/=redo\n", "print('E[beta_est_3]=\\n', estimated_ridge_beta_3)\n", "print('Difference :\\n', np.abs(estimated_ridge_beta-estimated_ridge_beta_3))"]}, {"cell_type": "markdown", "id": "different-costume", "metadata": {}, "source": ["\u00c7a marche !"]}, {"cell_type": "markdown", "id": "false-middle", "metadata": {}, "source": ["### c. Enfin de la vraie *data augmentation*"]}, {"cell_type": "markdown", "id": "protective-match", "metadata": {}, "source": ["Intuitivement, on s'attend \u00e0 ce qu'un nouveau $x_{\\text{new}}\\in\\mathbb{R}^n$ soit en r\u00e9alit\u00e9 proche d'un $x$, vecteur colonne de $X$ et que son label soit \u00e9galement proche. L'id\u00e9e va \u00eatre de virtuellement augmenter le nombre d'individus dans $X, y$ en perturbant les individus existants. Plus rigoureusement, cr\u00e9eons $m$ copies de nos vecteurs lignes de $X$ de la mani\u00e8re suivante : $x_{ij}^\\prime=x_i+\\epsilon_{ij}, i=1\\ldots p, j=1\\ldots m$ o\u00f9 le bruit est construit de la mani\u00e8re suivante : $\\epsilon_{ij}\\sim\\mathcal{N}(0, \\frac{\\lambda}{m}I_n)$. Les labels sont quant \u00e0 eux conserv\u00e9s.\n", "\n", "Notre nouvelle matrice $\\tilde{X}$ ne contient cette fois-ci QUE les versions perturb\u00e9es de nos donn\u00e9es. On v\u00e9rifiera qu'on obtient : \n", "\n", "$$\\sum_i\\sum_j x_{ij}^\\prime {x_{ij}^\\prime}^T=m(X^TX+\\lambda I_n).$$"]}, {"cell_type": "markdown", "id": "missing-complement", "metadata": {}, "source": ["## III. Ridge et le *dropout*"]}, {"cell_type": "markdown", "id": "celtic-makeup", "metadata": {}, "source": ["Comme nous l'avons d\u00e9j\u00e0 vu, une mani\u00e8re de faire de la r\u00e9gularisation est ce qu'on appelle le *dropout*. \u00c9tudions cela dans le cas de l'apprentissage d'un mod\u00e8le lin\u00e9aire. Soit $\\mathcal{X}\\subseteq\\mathbb{R}^d$ et $\\mathcal{Y}\\subseteq\\mathbb{R}$. L'objectif est donc de construire un mod\u00e8le lin\u00e9aire de $\\mathcal{X}$ dans $\\mathcal{Y}$ de la forme : $h:x\\mapsto \\langle \\omega, x\\rangle$, $\\omega\\in\\mathbb{R}^d$, qui minimise l'erreur quadratique :\n", "\n", "$$L(h)=\\mathbb{E}\\big[(Y-h(X))^2\\big],$$\n", "\n", "qu'on estime via un dataset $S_n$ :\n", "\n", "$$L_n(h)=\\frac{1}{n}\\sum_i (y_i-h(x_i))^2.$$\n", "\n", "L'id\u00e9e du *dropout* au moment de l'optimisation (i.e. de l'apprentissage), est de consid\u00e9rer la fonction $\\phi\\big(\\frac{\\delta\\odot z}{1-p}\\big)$ o\u00f9 $\\delta_i$ est une variable al\u00e9atoire qui suit une loi de Bernoulli de param\u00e8tre $1-p$ et est \u00e9chantillon\u00e9e pour chaque sample \u00e0 chaque it\u00e9ration de l'optimiseur et $\\odot$ est la multiplication \u00e9l\u00e9ment par \u00e9l\u00e9ment. Le param\u00e8tre $p$ donne l'importance du *dropout*. \u00c0 $0$, il n'y a pas de r\u00e9gularisation, proche de $1$ l'apprentissage ne fonctionne pas. Dans le cas d'une op\u00e9ration lin\u00e9aire le biais n'est g\u00e9n\u00e9ralement pas touch\u00e9 par le *dropout* (tout comme pour la p\u00e9nalit\u00e9 $\\ell_2$). Nous omettrons ici les consid\u00e9rations relatives \u00e0 ce dernier. Le facteur $1/(1-p)$ implique que bien que certaines dimensions tombent \u00e0 $0$ notre vecteur conserve la m\u00eame norme en esp\u00e9rance. Plus rigoureusement, nous avons :\n", "\n", "$$\\mathbb{E}\\big[\\delta_j/(1-p)\\big]=1.$$\n", "\n", "Le *dropout* est bien entendu \"d\u00e9sactiv\u00e9\" une fois l'apprentissage termin\u00e9 et le mod\u00e8le utilis\u00e9 pour faire des pr\u00e9dictions. \u00c9tudions l'esp\u00e9rance du gradient de notre mod\u00e8le :\n", "\n", "$$\\mathbb{E}\\Big[\\frac{\\partial L_n(\\omega)}{\\partial \\omega}\\Big]=-X^Ty+X^TX\\beta+\\frac{p}{1-p}D\\beta,$$\n", "\n", "o\u00f9 on a identifi\u00e9 la fonction $h$ \u00e0 ses param\u00e8tres $\\omega$ et o\u00f9 $D=\\text{diag}(\\lVert x_1\\rVert_2^2, \\ldots, \\lVert x_n\\rVert_2^2)$.\n", "\n", "En annulant le gradient en esp\u00e9rance, on obtient : \n", "\n", "$$\\hat{\\beta}=\\big(X^TX+\\frac{p}{1-p}D\\big)^{-1}X^ty$$\n", "\n", "qui peut \u00eatre vu comme une version g\u00e9n\u00e9ralis\u00e9e de Ridge."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 5}